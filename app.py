# app.py
# -*- coding: utf-8 -*-

from __future__ import annotations

from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Tuple

import pandas as pd
import streamlit as st

from modules import loader, analyzer


# ============================
# ê¸°ë³¸ ì„¤ì •
# ============================

st.set_page_config(
    page_title="ê³µë‹¨ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ Â· ì˜¨ì‹¤ê°€ìŠ¤ ê´€ë¦¬ ëŒ€ì‹œë³´ë“œ",
    layout="wide",
)

st.title("ê³µë‹¨ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ Â· ì˜¨ì‹¤ê°€ìŠ¤ ê´€ë¦¬ ëŒ€ì‹œë³´ë“œ")

DATA_DIR = Path("data")
ENERGY_DIR = DATA_DIR / "energy"


# ê¸°ê´€ ìˆœì„œ ë° ì‹œì„¤êµ° ì •ì˜ (ëŒ€ì‹œë³´ë“œ ê³µí†µ)
FACILITY_ORDER = [
    "ë³¸ì‚¬",
    "ì¤‘ì•™ë³‘ì›", "ë¶€ì‚°ë³‘ì›", "ê´‘ì£¼ë³‘ì›", "ëŒ€êµ¬ë³‘ì›", "ëŒ€ì „ë³‘ì›", "ì¸ì²œë³‘ì›",
    "êµìœ¡ì—°êµ¬ì›", "ë³´í›ˆì›",
    "ìˆ˜ì›ìš”ì–‘ì›", "ê´‘ì£¼ìš”ì–‘ì›", "ê¹€í•´ìš”ì–‘ì›", "ëŒ€êµ¬ìš”ì–‘ì›",
    "ëŒ€ì „ìš”ì–‘ì›", "ë‚¨ì–‘ì£¼ìš”ì–‘ì›", "ì›ì£¼ìš”ì–‘ì›", "ì „ì£¼ìš”ì–‘ì›",
    "ì¬í™œì²´ìœ¡ì„¼í„°", "íœ´ì–‘ì›",
]

MEDICAL_FACILITIES = [
    "ì¤‘ì•™ë³‘ì›", "ë¶€ì‚°ë³‘ì›", "ê´‘ì£¼ë³‘ì›", "ëŒ€êµ¬ë³‘ì›", "ëŒ€ì „ë³‘ì›", "ì¸ì²œë³‘ì›",
]
WELFARE_FACILITIES = [
    "ìˆ˜ì›ìš”ì–‘ì›", "ê´‘ì£¼ìš”ì–‘ì›", "ê¹€í•´ìš”ì–‘ì›", "ëŒ€êµ¬ìš”ì–‘ì›",
    "ëŒ€ì „ìš”ì–‘ì›", "ë‚¨ì–‘ì£¼ìš”ì–‘ì›", "ì›ì£¼ìš”ì–‘ì›", "ì „ì£¼ìš”ì–‘ì›",
]
OTHER_FACILITIES = [
    "ë³¸ì‚¬", "êµìœ¡ì—°êµ¬ì›", "ë³´í›ˆì›", "ì¬í™œì²´ìœ¡ì„¼í„°", "íœ´ì–‘ì›",
]


# ============================
# ê³µí†µ ìœ í‹¸
# ============================

def load_all_energy_data(base_dir: Path = ENERGY_DIR):
    """ì €ì¥ëœ ëª¨ë“  ì—°ë„ íŒŒì¼ì„ ë¡œë“œí•˜ì—¬
    - í‘œì¤€ ìŠ¤í‚¤ë§ˆ ë°ì´í„° df_all
    - íŒŒì¼ ë©”íƒ€ ì •ë³´
    - ë¡œë”© ì˜¤ë¥˜ ëª©ë¡
    ì„ ë°˜í™˜í•œë‹¤.
    """
    dfs: List[pd.DataFrame] = []
    meta_list: List[Dict[str, Any]] = []
    errors: List[Dict[str, Any]] = []

    for xlsx_path in sorted(base_dir.glob("*.xlsx")):
        try:
            df_std, year = loader.load_energy_xlsx(xlsx_path)
            dfs.append(df_std)

            stat = xlsx_path.stat()
            meta_list.append({
                "ì—°ë„": year,
                "íŒŒì¼ëª…": xlsx_path.name,
                "ê²½ë¡œ": str(xlsx_path),
                "ì—…ë¡œë“œì‹œê°„": datetime.fromtimestamp(stat.st_mtime).strftime(
                    "%Y-%m-%d %H:%M:%S"
                ),
            })
        except loader.EnergyDataError as e:
            errors.append({"íŒŒì¼ëª…": xlsx_path.name, "ì—ëŸ¬": str(e)})
        except Exception as e:
            errors.append({"íŒŒì¼ëª…": xlsx_path.name, "ì—ëŸ¬": f"ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}"})

    df_all = pd.concat(dfs, ignore_index=True) if dfs else None
    return df_all, meta_list, errors


def load_raw_year_data(year: int) -> pd.DataFrame | None:
    """ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ê´€ë¦¬ ì—‘ì…€ì˜ ì›ë³¸ êµ¬ì¡°(ì‹œíŠ¸1)ë¥¼ ê·¸ëŒ€ë¡œ ì½ì–´ì˜¨ë‹¤."""
    for p in ENERGY_DIR.glob("*.xlsx"):
        if str(year) in p.name:
            return loader.load_energy_raw_for_analysis(p)
    return None


def preprocess_uv_w(
    df_raw: pd.DataFrame,
) -> Tuple[pd.DataFrame, str, str, str, str, List[Dict[str, Any]]]:
    """ì›ë³¸ ì‹œíŠ¸ì˜ U/V/W ë° ê¸°ê´€ëª… ì»¬ëŸ¼ì„ ì •ì œí•œë‹¤.

    - ê¸°ê´€ëª…: ê³µë°± ì œê±°, NaN í–‰ ì œê±°
    - U/V/W: float ë³€í™˜, ë³€í™˜ ì‹¤íŒ¨ ê°’ì€ ì˜¤ë¥˜ ë¦¬ìŠ¤íŠ¸ì— ê¸°ë¡ í›„ NaN ì²˜ë¦¬
    - NaNì€ ì§‘ê³„ì—ì„œ ìë™ ì œì™¸ë˜ë©°, ê³„ì‚° ë¶ˆê°€ ì‹œ ê²°ê³¼ë¥¼ NaNìœ¼ë¡œ ë‚¨ê¸´ë‹¤.
    """
    errors: List[Dict[str, Any]] = []

    org_col = df_raw.columns[2]   # Cì—´
    U_col = df_raw.columns[20]    # Uì—´
    V_col = df_raw.columns[21]    # Vì—´
    W_col = df_raw.columns[22]    # Wì—´

    df = df_raw.copy()

    # ê¸°ê´€ëª… ì •ì œ
    df = df[df[org_col].notna()].copy()
    df[org_col] = df[org_col].astype(str).str.strip()

    def _to_numeric_with_log(series: pd.Series, col_label: str) -> pd.Series:
        s_raw = series
        s_str = s_raw.astype(str).str.strip()

        # ì™„ì „ ê³µë°±/ë¹ˆë¬¸ìì—´ì€ ê²°ì¸¡ìœ¼ë¡œ ì²˜ë¦¬
        empty_mask = s_str == ""
        s_str = s_str.mask(empty_mask, pd.NA)

        converted = pd.to_numeric(s_str, errors="coerce")

        # ë³€í™˜ ì˜¤ë¥˜(ìˆ«ìë¡œ í•´ì„ ë¶ˆê°€) ë¡œê¹…
        err_mask = s_str.notna() & converted.isna()
        if err_mask.any():
            for idx in s_raw[err_mask].index:
                errors.append({
                    "row": int(idx),
                    "ì»¬ëŸ¼": str(col_label),
                    "ê°’": s_raw.loc[idx],
                })
        return converted

    df[U_col] = _to_numeric_with_log(df[U_col], U_col)
    df[V_col] = _to_numeric_with_log(df[V_col], V_col)
    df[W_col] = _to_numeric_with_log(df[W_col], W_col)

    return df, org_col, U_col, V_col, W_col, errors


def detect_last_month_with_data(df_raw: pd.DataFrame) -> int | None:
    """ì›”ë³„ ì—´(1ì›”~12ì›”) ì¤‘ ì‹¤ì œ ìˆ«ì ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ” ê°€ì¥ ë§ˆì§€ë§‰ ì›”ì„ ë°˜í™˜."""
    last_month: int | None = None

    month_cols = [
        c for c in df_raw.columns
        if isinstance(c, str) and c.endswith("ì›”") and c[0].isdigit()
    ]

    for c in month_cols:
        s_raw = df_raw[c]
        s_str = s_raw.astype(str).str.strip()
        empty_mask = s_str == ""
        s_str = s_str.mask(empty_mask, pd.NA)
        converted = pd.to_numeric(s_str, errors="coerce")

        if converted.notna().any():
            try:
                m = int(str(c).replace("ì›”", ""))
                if (last_month is None) or (m > last_month):
                    last_month = m
            except ValueError:
                continue

    return last_month


# ============================
# ì„¸ì…˜ ìƒíƒœ
# ============================

if "processed_uploads" not in st.session_state:
    st.session_state["processed_uploads"] = set()


# ============================
# íƒ­ êµ¬ì„±
# ============================

tab_dashboard, tab_debug = st.tabs(
    ["ğŸ“Š ëŒ€ì‹œë³´ë“œ", "ğŸ”§ ë””ë²„ê·¸/ì§„ë‹¨"]
)


# ============================================================
# ğŸ“Š 1) ëŒ€ì‹œë³´ë“œ íƒ­
# ============================================================

with tab_dashboard:

    # -----------------------------
    # ì§„í–‰ì¤‘ ê¸°ëŠ¥ ë°˜ì˜ í˜„í™© í‘œì‹œ
    # -----------------------------
    with st.expander("ğŸ› ï¸ í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ê¸°ëŠ¥ ë°˜ì˜ í˜„í™©"):
        st.markdown(
            """\
            # ğŸ”§ ê¸°ëŠ¥ ë°˜ì˜ í˜„í™©

            - ìƒë‹¨ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì¶”ì´(í•„í„° + ê·¸ë˜í”„ 2ê°œ) ë ˆì´ì•„ì›ƒ ìœ ì§€
            - ê¸°ì¤€ë°°ì¶œëŸ‰ ê¸°ëŠ¥ ì „ë©´ ì œê±°
            - ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë¶„ì„(ì‹œíŠ¸1 ê¸°ë°˜) ë° í”¼ë“œë°±(ì‹œíŠ¸2 ê¸°ë°˜) ë¡œì§ ë³´ì™„
            - ëª¨ë“  ê³„ì‚°ì€ ì—…ë¡œë“œëœ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì—‘ì…€ì˜ U/V/W ì—´ ê¸°ì¤€
            """
        )

    # ------------------------------
    # íŒŒì¼ ì—…ë¡œë“œ
    # ------------------------------
    st.markdown("### ì›”ë³„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ íŒŒì¼ ì—…ë¡œë“œ")

    upload_col1, upload_col2 = st.columns([1.2, 2])
    new_file_processed = False

    with upload_col1:
        uploaded_files = st.file_uploader(
            "ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ê´€ë¦¬ .xlsx íŒŒì¼ ì—…ë¡œë“œ",
            type=["xlsx"],
            accept_multiple_files=True,
        )

        if uploaded_files:
            for f in uploaded_files:
                if f.name in st.session_state["processed_uploads"]:
                    continue
                try:
                    _, year, saved_path = loader.process_uploaded_energy_file(
                        file_obj=f,
                        original_filename=f.name,
                        base_dir=ENERGY_DIR,
                    )
                    st.session_state["processed_uploads"].add(f.name)
                    st.success(f"{f.name} ({year}) ì—…ë¡œë“œ ì™„ë£Œ")
                    new_file_processed = True
                except Exception as e:
                    st.error(f"ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")

        if new_file_processed:
            st.rerun()

    # ì €ì¥ëœ íŒŒì¼ ëª©ë¡
    with upload_col2:
        st.markdown("#### ì €ì¥ëœ íŒŒì¼ ëª©ë¡")

        df_all, files_meta, load_errors = load_all_energy_data()

        if files_meta:
            df_files = pd.DataFrame(files_meta).sort_values(
                ["ì—°ë„", "ì—…ë¡œë“œì‹œê°„"], ascending=[False, False]
            )
            st.table(df_files[["ì—°ë„", "íŒŒì¼ëª…", "ì—…ë¡œë“œì‹œê°„"]])
        else:
            st.info("ì €ì¥ëœ íŒŒì¼ ì—†ìŒ")

    st.markdown("---")

    if df_all is None:
        st.warning("ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # -----------------------------
    # ìƒë‹¨ ê·¸ë˜í”„/ì§€í‘œìš© ì§‘ê³„ ë°ì´í„°
    # -----------------------------
    datasets = analyzer.build_dashboard_datasets(df_all)
    annual_total = datasets["annual_total"]
    annual_by_agency = datasets["annual_by_agency"]
    monthly_total = datasets["monthly_total"]
    monthly_by_agency = datasets["monthly_by_agency"]

    years = sorted(df_all["ì—°ë„"].dropna().unique().tolist())
    default_year = max(years)

    # ============================================================
    # 1) ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì¶”ì´ (ê¸°ì¡´ ìƒë‹¨ ì˜ì—­ ìœ ì§€, ê¸°ì¤€ë°°ì¶œëŸ‰ ì œê±°)
    # ============================================================

    st.markdown("## ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì¶”ì´")

    filter_col, main_col = st.columns([1, 3])

    # ----- ì¢Œì¸¡ í•„í„° -----
    with filter_col:
        st.subheader("í•„í„°")

        view_scope = st.radio("ë³´ê¸° ë²”ìœ„", ["ê³µë‹¨ ì „ì²´", "ê¸°ê´€ë³„"], index=0)

        selected_year = st.selectbox(
            "ì´í–‰ì—°ë„ ì„ íƒ",
            years,
            index=years.index(default_year),
        )

        selected_org = None
        if view_scope == "ê¸°ê´€ë³„":
            org_list = df_all["ê¸°ê´€ëª…"].dropna().unique().tolist()
            ordered = [o for o in FACILITY_ORDER if o in org_list]
            others = sorted([o for o in org_list if o not in FACILITY_ORDER])
            org_options = ordered + others
            if not org_options:
                st.warning("ê¸°ê´€ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                selected_org = st.selectbox("ê¸°ê´€ ì„ íƒ", org_options)

        st.markdown("ì—ë„ˆì§€ ì¢…ë¥˜ í•„í„° (ì¶”í›„ í™•ì¥ìš©)")
        _ = st.selectbox("ì—ë„ˆì§€ ì¢…ë¥˜", ["ì „ì²´"])

    # ----- ìš°ì¸¡ ìš”ì•½ íŒ¨ë„ + ê·¸ë˜í”„ -----
    with main_col:
        # ì—°ê°„ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰(ê³µë‹¨ ê¸°ì¤€)
        annual_row = annual_total[annual_total["ì—°ë„"] == selected_year]
        if not annual_row.empty:
            total_emission = float(annual_row["ì—°ê°„ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰"].iloc[0])
        else:
            total_emission = None

        # ì „ë…„ ëŒ€ë¹„ ì¦ê°ë¥ 
        prev_year = int(selected_year) - 1
        prev_row = annual_total[annual_total["ì—°ë„"] == prev_year]
        if (total_emission is not None) and (not prev_row.empty):
            prev_emission = float(prev_row["ì—°ê°„ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰"].iloc[0])
            if prev_emission != 0:
                yoy_change = (total_emission - prev_emission) / prev_emission * 100
            else:
                yoy_change = None
        else:
            yoy_change = None

        k1, k2, k3 = st.columns(3)
        k1.metric("ì„ íƒ ì—°ë„", f"{selected_year}ë…„")
        k2.metric(
            "ì—°ê°„ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰(ê³µë‹¨)",
            "-" if total_emission is None else f"{total_emission:,.0f} tCO2eq",
        )
        k3.metric(
            "ì „ë…„ ëŒ€ë¹„ ì¦ê°ë¥ ",
            "-" if yoy_change is None else f"{yoy_change:,.1f} %",
        )

        # ê·¸ë˜í”„ ë°ì´í„°
        if view_scope == "ê³µë‹¨ ì „ì²´":
            monthly_df = monthly_total[monthly_total["ì—°ë„"] == selected_year]
            recent_df, _ = analyzer.get_recent_years_ghg(
                annual_total, base_year=int(selected_year)
            )
        else:
            if selected_org is not None:
                monthly_df = monthly_by_agency[
                    (monthly_by_agency["ì—°ë„"] == selected_year)
                    & (monthly_by_agency["ê¸°ê´€ëª…"] == selected_org)
                ]
                annual_sel = annual_by_agency[
                    annual_by_agency["ê¸°ê´€ëª…"] == selected_org
                ]
                recent_df, _ = analyzer.get_recent_years_ghg(
                    annual_sel, base_year=int(selected_year)
                )
            else:
                monthly_df = pd.DataFrame()
                recent_df = pd.DataFrame()

        c1, c2 = st.columns(2)

        with c1:
            st.markdown("#### ì´í–‰ì—°ë„ ì›”ë³„ ì˜¨ì‹¤ê°€ìŠ¤ ì¶”ì´")
            if not monthly_df.empty:
                chart_month = (
                    monthly_df.sort_values("ì›”")[["ì›”", "ì›”ë³„ ì˜¨ì‹¤ê°€ìŠ¤ í™˜ì‚°ëŸ‰"]]
                    .set_index("ì›”")
                )
                st.line_chart(chart_month)
            else:
                st.info("ì„ íƒ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ì›”ë³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        with c2:
            st.markdown("#### ìµœê·¼ 5ê°œë…„ ì—°ê°„ ë°°ì¶œëŸ‰ ì¶”ì´")
            if not recent_df.empty:
                chart_recent = (
                    recent_df.sort_values("ì—°ë„")[["ì—°ë„", "ì—°ê°„ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰"]]
                    .set_index("ì—°ë„")
                )
                st.bar_chart(chart_recent)
            else:
                st.info("ì„ íƒ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ì—°ê°„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ============================================================
    # 2) ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë¶„ì„ (ì‹œíŠ¸1 êµ¬ì¡° ê¸°ë°˜)
    # ============================================================

    st.markdown("---")
    st.markdown("## ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë¶„ì„")

    raw_df_original = load_raw_year_data(int(selected_year))
    if raw_df_original is None:
        st.error(f"{selected_year}ë…„ ì›ë³¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    raw_df, org_col, U_col, V_col, W_col, preprocess_errors = preprocess_uv_w(
        raw_df_original
    )

    # ---- 3-1) ê³µë‹¨ ì „ì²´ ê¸°ì¤€ ----
    total_U = float(raw_df[U_col].sum(skipna=True))
    total_V = float(raw_df[V_col].sum(skipna=True))

    # 3ê°œë…„ í‰ê·  ëŒ€ë¹„ ì¦ê°ë¥  (Uì—´ ê¸°ì¤€)
    past_years = [
        int(selected_year) - 3,
        int(selected_year) - 2,
        int(selected_year) - 1,
    ]
    past_u_values: List[float] = []
    for y in past_years:
        df_past_raw = load_raw_year_data(y)
        if df_past_raw is not None:
            df_past, p_org, p_U, p_V, p_W, err = preprocess_uv_w(df_past_raw)
            past_u_values.append(float(df_past[p_U].sum(skipna=True)))

    if past_u_values:
        past_avg_U = sum(past_u_values) / len(past_u_values)
        if past_avg_U != 0:
            U_change_rate = (total_U - past_avg_U) / past_avg_U * 100
        else:
            U_change_rate = None
    else:
        past_avg_U = None
        U_change_rate = None

    st.markdown("### ê³µë‹¨ ì „ì²´ ê¸°ì¤€")

    k1, k2, k3 = st.columns(3)
    k1.metric("ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(í˜„ì¬ ê¸°ì¤€)", f"{total_U:,.0f}")
    k2.metric("ë©´ì ë‹¹ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰", f"{total_V:,.0f}")
    k3.metric(
        "3ê°œë…„ í‰ê·  ëŒ€ë¹„ ì¦ê°ë¥ ",
        "-" if U_change_rate is None else f"{U_change_rate:,.1f} %",
    )

    # í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(W ê¸°ì¤€)
    st.markdown("#### í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(ì—°ë©´ì  W ê¸°ì¤€)")

    def avg_group(names: List[str]) -> float | None:
        df_tmp = raw_df[raw_df[org_col].isin(names)]
        if df_tmp.empty:
            return None
        return float(df_tmp[W_col].mean(skipna=True))

    med_avg = avg_group(MEDICAL_FACILITIES)
    wel_avg = avg_group(WELFARE_FACILITIES)
    oth_avg = avg_group(OTHER_FACILITIES)

    g1, g2, g3 = st.columns(3)
    g1.metric("ì˜ë£Œì‹œì„¤ í‰ê· (W)", "-" if med_avg is None else f"{med_avg:,.1f}")
    g2.metric("ë³µì§€ì‹œì„¤ í‰ê· (W)", "-" if wel_avg is None else f"{wel_avg:,.1f}")
    g3.metric("ê¸°íƒ€ì‹œì„¤ í‰ê· (W)", "-" if oth_avg is None else f"{oth_avg:,.1f}")

    # ---- 3-2) ì†Œì†ê¸°êµ¬ë³„ ë¶„ì„ ----
    st.markdown("### ì†Œì†ê¸°êµ¬ë³„ ë¶„ì„")

    df_group = (
        raw_df.groupby(org_col)
        .agg(
            U_sum=(U_col, "sum"),
            V_sum=(V_col, "sum"),
            W_mean=(W_col, "mean"),
        )
        .reset_index()
        .rename(columns={org_col: "êµ¬ë¶„"})
    )

    def facility_type(name: str) -> str:
        if name in MEDICAL_FACILITIES:
            return "ì˜ë£Œì‹œì„¤"
        if name in WELFARE_FACILITIES:
            return "ë³µì§€ì‹œì„¤"
        if name in OTHER_FACILITIES:
            return "ê¸°íƒ€ì‹œì„¤"
        return "ê¸°íƒ€ì‹œì„¤"

    df_group["ì‹œì„¤êµ¬ë¶„"] = df_group["êµ¬ë¶„"].apply(facility_type)

    # ê³µë‹¨ ì „ì²´ ì‚¬ìš©ëŸ‰ ëŒ€ë¹„ ë¶„í¬ ë¹„ìœ¨ U(ê¸°ê´€)/U(ì „ì²´)
    df_group["ê³µë‹¨ ì „ì²´ ì‚¬ìš©ëŸ‰ ëŒ€ë¹„ ë¶„í¬ ë¹„ìœ¨"] = (
        df_group["U_sum"] / total_U * 100 if total_U != 0 else pd.NA
    )

    # ì‹œì„¤êµ°ë³„ Wí‰ê·  ëŒ€ë¹„ ì‚¬ìš©ë¹„ìœ¨
    def avg_ratio(row):
        if row["ì‹œì„¤êµ¬ë¶„"] == "ì˜ë£Œì‹œì„¤":
            return row["W_mean"] / med_avg if (med_avg not in (None, 0)) else pd.NA
        if row["ì‹œì„¤êµ¬ë¶„"] == "ë³µì§€ì‹œì„¤":
            return row["W_mean"] / wel_avg if (wel_avg not in (None, 0)) else pd.NA
        return row["W_mean"] / oth_avg if (oth_avg not in (None, 0)) else pd.NA

    df_group["í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(W) ëŒ€ë¹„ ì‚¬ìš©ë¹„ìœ¨"] = df_group.apply(avg_ratio, axis=1)

    # ê¸°ê´€ë³„ 3ê°œë…„ í‰ê·  ëŒ€ë¹„ ì¦ê°ë¥ 
    def three_year_rate(name: str) -> float | None:
        vals: List[float] = []
        for y in past_years:
            dfp_raw = load_raw_year_data(y)
            if dfp_raw is not None:
                dfp, p_org, p_U, p_V, p_W, err = preprocess_uv_w(dfp_raw)
                dfp = dfp[dfp[p_org].notna()].copy()
                dfp[p_org] = dfp[p_org].astype(str).str.strip()
                vals.append(float(dfp[dfp[p_org] == name][p_U].sum(skipna=True)))

        if vals:
            avg_past = sum(vals) / len(vals)
            now_val = float(
                df_group.loc[df_group["êµ¬ë¶„"] == name, "U_sum"].iloc[0]
            )
            if avg_past != 0:
                return (now_val - avg_past) / avg_past * 100
        return None

    df_group["3ê°œë…„ í‰ê·  ëŒ€ë¹„ ì¦ê°ë¥ "] = df_group["êµ¬ë¶„"].apply(three_year_rate)

    # í‘œ ì¶œë ¥ìš© ì»¬ëŸ¼ êµ¬ì„± ë° ì •ë ¬
    df_group_display = df_group.copy()
    df_group_display = df_group_display.rename(columns={
        "U_sum": "ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(í˜„ì¬ ê¸°ì¤€)",
        "V_sum": "ë©´ì ë‹¹ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰",
        "W_mean": "Wí‰ê· ",
    })

    df_group_display["êµ¬ë¶„"] = pd.Categorical(
        df_group_display["êµ¬ë¶„"], categories=FACILITY_ORDER, ordered=True
    )
    df_group_display = df_group_display.sort_values("êµ¬ë¶„")

    cols_order = [
        "êµ¬ë¶„",
        "ì‹œì„¤êµ¬ë¶„",
        "ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(í˜„ì¬ ê¸°ì¤€)",
        "ë©´ì ë‹¹ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰",
        "ê³µë‹¨ ì „ì²´ ì‚¬ìš©ëŸ‰ ëŒ€ë¹„ ë¶„í¬ ë¹„ìœ¨",
        "í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(W) ëŒ€ë¹„ ì‚¬ìš©ë¹„ìœ¨",
        "3ê°œë…„ í‰ê·  ëŒ€ë¹„ ì¦ê°ë¥ ",
    ]

    st.dataframe(
        df_group_display[cols_order].style.format(na_rep="-"),
        use_container_width=True,
    )

    # ============================================================
    # 3) í”¼ë“œë°± (ì‹œíŠ¸2 êµ¬ì¡° ê¸°ë°˜)
    # ============================================================

    st.markdown("## í”¼ë“œë°±")

    # ---- 4-1) ê³µë‹¨ ì „ì²´ ê¸°ì¤€ ----
    st.markdown("### ê³µë‹¨ ì „ì²´ ê¸°ì¤€")

    ê¸°ì¤€ë‹¬ = detect_last_month_with_data(raw_df_original)

    f1 = st.columns(1)[0]
    f1.metric("ê¸°ì¤€ ë‹¬", f"{ê¸°ì¤€ë‹¬}ì›”" if ê¸°ì¤€ë‹¬ is not None else "-")

    # ---- 4-2) ì†Œì†ê¸°êµ¬ë³„ í”¼ë“œë°± ----
    st.markdown("### ì†Œì†ê¸°êµ¬ë³„ í”¼ë“œë°±")

    df_fb = df_group_display.copy()

    # ì‚¬ìš©ëŸ‰ ë¶„í¬ ìˆœìœ„ (U í•©ê³„ ë¹„ìœ¨ ê¸°ì¤€)
    df_fb["ì‚¬ìš©ëŸ‰ ë¶„í¬ ìˆœìœ„"] = df_fb["ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(í˜„ì¬ ê¸°ì¤€)"].rank(
        ascending=False, method="dense"
    )

    # ì—ë„ˆì§€ 3ê°œë…„ í‰ê·  ì¦ê°€ ìˆœìœ„
    df_fb["ì—ë„ˆì§€ 3ê°œë…„ í‰ê·  ì¦ê°€ ìˆœìœ„"] = df_fb["3ê°œë…„ í‰ê·  ëŒ€ë¹„ ì¦ê°ë¥ "].rank(
        ascending=False, method="dense"
    )

    # í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(W) ê¸°ì¤€ ìˆœìœ„
    df_fb["í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(W) ê¸°ì¤€ ìˆœìœ„"] = df_fb[
        "í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(W) ëŒ€ë¹„ ì‚¬ìš©ë¹„ìœ¨"
    ].rank(ascending=False, method="dense")

    # ê¶Œì¥ ê°ì¶•ëŸ‰: Uì¦ê°€ë¶„ + Wì´ˆê³¼ë¶„ ê¸°ë°˜
    def recommended_reduction(row) -> float | None:
        # ê¸°ê´€ë³„ 3ê°œë…„ í‰ê·  U
        name = row["êµ¬ë¶„"]
        vals: List[float] = []
        for y in past_years:
            dfp_raw = load_raw_year_data(y)
            if dfp_raw is not None:
                dfp, p_org, p_U, p_V, p_W, err = preprocess_uv_w(dfp_raw)
                dfp = dfp[dfp[p_org].notna()].copy()
                dfp[p_org] = dfp[p_org].astype(str).str.strip()
                vals.append(float(dfp[dfp[p_org] == name][p_U].sum(skipna=True)))

        if vals:
            avg_u = sum(vals) / len(vals)
        else:
            avg_u = None

        current_u = row["ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(í˜„ì¬ ê¸°ì¤€)"]

        # U ì¦ê°€ë¶„(ì–‘ìˆ˜ì¼ ë•Œë§Œ)
        if (avg_u is not None) and (avg_u > 0):
            delta_u = max(current_u - avg_u, 0)
            u_ratio = delta_u / avg_u
        else:
            delta_u = 0.0
            u_ratio = 0.0

        # ì‹œì„¤êµ° í‰ê·  ëŒ€ë¹„ W ì´ˆê³¼ë¶„
        group = row["ì‹œì„¤êµ¬ë¶„"]
        if group == "ì˜ë£Œì‹œì„¤":
            base_w = med_avg
        elif group == "ë³µì§€ì‹œì„¤":
            base_w = wel_avg
        else:
            base_w = oth_avg

        w_mean = row["Wí‰ê· "]
        if base_w not in (None, 0) and pd.notna(w_mean):
            excess_w_ratio = max(w_mean / base_w - 1, 0)
        else:
            excess_w_ratio = 0.0

        # ê¶Œì¥ ê°ì¶•ëŸ‰: í˜„ì¬ ì‚¬ìš©ëŸ‰ Ã— (Uì¦ê°€ìœ¨ + Wì´ˆê³¼ìœ¨)
        scale = u_ratio + excess_w_ratio
        if scale <= 0:
            return 0.0
        return float(current_u * scale)

    df_fb["ê¶Œì¥ ê°ì¶•ëŸ‰"] = df_fb.apply(recommended_reduction, axis=1)

    # ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì¦ê°€ ì‚¬ìœ  ì œì¶œ ëŒ€ìƒ
    def need_reason(row) -> str:
        cond1 = pd.notna(row["3ê°œë…„ í‰ê·  ëŒ€ë¹„ ì¦ê°ë¥ "]) and row["3ê°œë…„ í‰ê·  ëŒ€ë¹„ ì¦ê°ë¥ "] > 0
        cond2 = (
            pd.notna(row["í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(W) ëŒ€ë¹„ ì‚¬ìš©ë¹„ìœ¨"])
            and row["í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(W) ëŒ€ë¹„ ì‚¬ìš©ë¹„ìœ¨"] > 1
        )
        return "O" if (cond1 or cond2) else "X"

    df_fb["ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì¦ê°€ ì‚¬ìœ  ì œì¶œ ëŒ€ìƒ"] = df_fb.apply(need_reason, axis=1)

    fb_cols = [
        "êµ¬ë¶„",
        "ì‚¬ìš©ëŸ‰ ë¶„í¬ ìˆœìœ„",
        "ì—ë„ˆì§€ 3ê°œë…„ í‰ê·  ì¦ê°€ ìˆœìœ„",
        "í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(W) ê¸°ì¤€ ìˆœìœ„",
        "ê¶Œì¥ ê°ì¶•ëŸ‰",
        "ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì¦ê°€ ì‚¬ìœ  ì œì¶œ ëŒ€ìƒ",
    ]

    st.dataframe(
        df_fb[fb_cols].style.format(na_rep="-"),
        use_container_width=True,
    )


# ============================================================
# ğŸ”§ 2) ë””ë²„ê·¸ / ì§„ë‹¨ íƒ­
# ============================================================

with tab_debug:

    st.header("ë””ë²„ê·¸ / êµ¬ì¡° ì§„ë‹¨")

    st.markdown("### íŒŒì¼ êµ¬ì¡° ì§„ë‹¨")
    uploaded_debug_file = st.file_uploader("ì—‘ì…€ êµ¬ì¡° ì§„ë‹¨ íŒŒì¼ ì—…ë¡œë“œ (.xlsx)", type=["xlsx"])
    if uploaded_debug_file:
        from tempfile import NamedTemporaryFile

        with NamedTemporaryFile(delete=False, suffix=".xlsx") as tmp:
            tmp.write(uploaded_debug_file.read())
            tmp_path = Path(tmp.name)

        try:
            res = loader.validate_excel_file(tmp_path)
            st.json(res)
        except Exception as e:
            st.error(f"ì§„ë‹¨ ì˜¤ë¥˜: {e}")

    st.markdown("---")

    # ì‹¤í–‰ í™˜ê²½ ì§„ë‹¨ â€” loader.py í™•ì¸
    with st.expander("ğŸ§ª ì‹¤í–‰ í™˜ê²½ ì§„ë‹¨: loader.py í™•ì¸"):
        import modules.loader as ld
        import inspect

        st.subheader("ğŸ“Œ Streamlitì´ ì‚¬ìš© ì¤‘ì¸ loader.py ê²½ë¡œ")
        st.code(ld.__file__)

        st.subheader("ğŸ“Œ í•¨ìˆ˜ ëª©ë¡")
        st.write(dir(ld))

        st.subheader("ğŸ“Œ ì‹¤ì œ loader.py ì†ŒìŠ¤ ì½”ë“œ")
        try:
            st.code(inspect.getsource(ld), language="python")
        except Exception:
            st.error("ì†ŒìŠ¤ ì½”ë“œë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
