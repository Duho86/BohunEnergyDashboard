# app.py
# -*- coding: utf-8 -*-

from __future__ import annotations

from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any

import pandas as pd
import streamlit as st

from modules import loader, analyzer, feedback, baseline as baseline_mod


# ============================
# ê¸°ë³¸ ì„¤ì •
# ============================

st.set_page_config(
    page_title="ê³µë‹¨ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ Â· ì˜¨ì‹¤ê°€ìŠ¤ ê´€ë¦¬ ëŒ€ì‹œë³´ë“œ",
    layout="wide",
)

st.title("ê³µë‹¨ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ Â· ì˜¨ì‹¤ê°€ìŠ¤ ê´€ë¦¬ ëŒ€ì‹œë³´ë“œ")

DATA_DIR = Path("data")
ENERGY_DIR = DATA_DIR / "energy"
BASELINE_PATH = DATA_DIR / "baseline.json"


# ê¸°ê´€ ìˆœì„œ ë° ì‹œì„¤êµ° ì •ì˜ (ëŒ€ì‹œë³´ë“œ ê³µí†µ)
FACILITY_ORDER = [
    "ë³¸ì‚¬",
    "ì¤‘ì•™ë³‘ì›", "ë¶€ì‚°ë³‘ì›", "ê´‘ì£¼ë³‘ì›", "ëŒ€êµ¬ë³‘ì›", "ëŒ€ì „ë³‘ì›", "ì¸ì²œë³‘ì›",
    "êµìœ¡ì—°êµ¬ì›", "ë³´í›ˆì›",
    "ìˆ˜ì›ìš”ì–‘ì›", "ê´‘ì£¼ìš”ì–‘ì›", "ê¹€í•´ìš”ì–‘ì›", "ëŒ€êµ¬ìš”ì–‘ì›",
    "ëŒ€ì „ìš”ì–‘ì›", "ë‚¨ì–‘ì£¼ìš”ì–‘ì›", "ì›ì£¼ìš”ì–‘ì›", "ì „ì£¼ìš”ì–‘ì›",
    "ì¬í™œì²´ìœ¡ì„¼í„°", "íœ´ì–‘ì›",
]

MEDICAL_FACILITIES = [
    "ì¤‘ì•™ë³‘ì›", "ë¶€ì‚°ë³‘ì›", "ê´‘ì£¼ë³‘ì›", "ëŒ€êµ¬ë³‘ì›", "ëŒ€ì „ë³‘ì›", "ì¸ì²œë³‘ì›"
]
WELFARE_FACILITIES = [
    "ìˆ˜ì›ìš”ì–‘ì›", "ê´‘ì£¼ìš”ì–‘ì›", "ê¹€í•´ìš”ì–‘ì›", "ëŒ€êµ¬ìš”ì–‘ì›",
    "ëŒ€ì „ìš”ì–‘ì›", "ë‚¨ì–‘ì£¼ìš”ì–‘ì›", "ì›ì£¼ìš”ì–‘ì›", "ì „ì£¼ìš”ì–‘ì›",
]
OTHER_FACILITIES = [
    "ë³¸ì‚¬", "êµìœ¡ì—°êµ¬ì›", "ë³´í›ˆì›", "ì¬í™œì²´ìœ¡ì„¼í„°", "íœ´ì–‘ì›"
]


# ============================
# ê³µí†µ ìœ í‹¸
# ============================

def load_all_energy_data(base_dir: Path = ENERGY_DIR):
    """
    ì €ì¥ëœ ëª¨ë“  ì—°ë„ íŒŒì¼ì„ ë¡œë“œí•˜ì—¬
    - í‘œì¤€ ìŠ¤í‚¤ë§ˆ ë°ì´í„° df_all
    - íŒŒì¼ ë©”íƒ€ ì •ë³´
    - ë¡œë”© ì˜¤ë¥˜ ëª©ë¡
    ì„ ë°˜í™˜í•œë‹¤.
    """
    dfs: List[pd.DataFrame] = []
    meta_list: List[Dict[str, Any]] = []
    errors: List[Dict[str, Any]] = []

    for xlsx_path in sorted(base_dir.glob("*.xlsx")):
        try:
            df_std, year = loader.load_energy_xlsx(xlsx_path)
            dfs.append(df_std)

            stat = xlsx_path.stat()
            meta_list.append({
                "ì—°ë„": year,
                "íŒŒì¼ëª…": xlsx_path.name,
                "ê²½ë¡œ": str(xlsx_path),
                "ì—…ë¡œë“œì‹œê°„": datetime.fromtimestamp(stat.st_mtime).strftime(
                    "%Y-%m-%d %H:%M:%S"
                ),
            })
        except loader.EnergyDataError as e:
            errors.append({"íŒŒì¼ëª…": xlsx_path.name, "ì—ëŸ¬": str(e)})
        except Exception as e:
            errors.append({"íŒŒì¼ëª…": xlsx_path.name, "ì—ëŸ¬": f"ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}"})

    df_all = pd.concat(dfs, ignore_index=True) if dfs else None
    return df_all, meta_list, errors


def load_raw_year_data(year: int) -> pd.DataFrame | None:
    """
    'ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ê´€ë¦¬.xlsx' ì›ë³¸ êµ¬ì¡°ë¥¼ ê·¸ëŒ€ë¡œ ì½ì–´ì˜¤ëŠ” í•¨ìˆ˜.
    (U/V/W ë° ì›”ë³„ ë°ì´í„° ë¶„ì„ìš©)
    """
    for p in ENERGY_DIR.glob("*.xlsx"):
        if str(year) in p.name:
            return loader.load_energy_raw_for_analysis(p)
    return None


def preprocess_uv_w(df_raw: pd.DataFrame):
    """
    U/V/W ì—´ ë° ê¸°ê´€ëª…ì— ëŒ€í•´
    - ê¸°ê´€ëª… ê³µë°± ì œê±°
    - U/V/W â†’ float ë³€í™˜
    - ë³€í™˜ ì‹¤íŒ¨ ê°’ì€ ì˜¤ë¥˜ ë¦¬ìŠ¤íŠ¸ì— ê¸°ë¡ í›„ NaN ì²˜ë¦¬
    (ì§‘ê³„ ì‹œ NaNì€ ìë™ ì œì™¸)
    """
    errors: List[Dict[str, Any]] = []

    org_col = df_raw.columns[2]
    U_col = df_raw.columns[20]
    V_col = df_raw.columns[21]
    W_col = df_raw.columns[22]

    df = df_raw.copy()

    # ê¸°ê´€ëª… ì •ì œ
    df = df[df[org_col].notna()].copy()
    df[org_col] = df[org_col].astype(str).str.strip()

    def _to_numeric_with_log(series: pd.Series, col_label: str) -> pd.Series:
        s_raw = series
        s_str = s_raw.astype(str).str.strip()

        # ì™„ì „ ê³µë°±/ë¹ˆë¬¸ìì—´ì€ ê²°ì¸¡ìœ¼ë¡œ ì²˜ë¦¬
        empty_mask = s_str == ""
        s_str = s_str.mask(empty_mask, pd.NA)

        converted = pd.to_numeric(s_str, errors="coerce")

        # ë³€í™˜ ì˜¤ë¥˜(ìˆ«ìë¡œ í•´ì„ ë¶ˆê°€) ë¡œê¹…
        err_mask = s_str.notna() & converted.isna()
        if err_mask.any():
            for idx in s_raw[err_mask].index:
                errors.append({
                    "row": int(idx),
                    "ì»¬ëŸ¼": str(col_label),
                    "ê°’": s_raw.loc[idx],
                })
        return converted

    df[U_col] = _to_numeric_with_log(df[U_col], U_col)
    df[V_col] = _to_numeric_with_log(df[V_col], V_col)
    df[W_col] = _to_numeric_with_log(df[W_col], W_col)

    return df, org_col, U_col, V_col, W_col, errors


def detect_last_month_with_data(df_raw: pd.DataFrame) -> int | None:
    """
    'ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ê´€ë¦¬' ì›ë³¸ì—ì„œ
    - '1ì›”' ~ '12ì›”' ì»¬ëŸ¼ ì¤‘
    - ì‹¤ì œ ìˆ«ì ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ” ê°€ì¥ ë§ˆì§€ë§‰ ì›” ë²ˆí˜¸ë¥¼ ë°˜í™˜.
    """
    last_month: int | None = None

    month_cols = [
        c for c in df_raw.columns
        if isinstance(c, str) and c.endswith("ì›”") and c[0].isdigit()
    ]

    for c in month_cols:
        s_raw = df_raw[c]
        s_str = s_raw.astype(str).str.strip()
        empty_mask = s_str == ""
        s_str = s_str.mask(empty_mask, pd.NA)
        converted = pd.to_numeric(s_str, errors="coerce")

        if converted.notna().any():
            try:
                m = int(str(c).replace("ì›”", ""))
                if (last_month is None) or (m > last_month):
                    last_month = m
            except ValueError:
                continue

    return last_month


# ============================
# ì„¸ì…˜ ìƒíƒœ
# ============================

if "processed_uploads" not in st.session_state:
    st.session_state["processed_uploads"] = set()

# baseline ë¡œë“œ (ì‚¬ìš©ì ì…ë ¥ê°’ë§Œ ì‚¬ìš©)
baseline_records = baseline_mod.load_baseline_records(BASELINE_PATH)
baseline_map = baseline_mod.get_baseline_map(baseline_records)


# ============================
# íƒ­ êµ¬ì„±
# ============================

tab_dashboard, tab_baseline, tab_debug = st.tabs(
    ["ğŸ“Š ëŒ€ì‹œë³´ë“œ", "âš™ï¸ ê¸°ì¤€ë°°ì¶œëŸ‰ ê´€ë¦¬", "ğŸ”§ ë””ë²„ê·¸/ì§„ë‹¨"]
)

# ============================================================
# ğŸ“Š 1) ëŒ€ì‹œë³´ë“œ íƒ­
# ============================================================

with tab_dashboard:

    # -----------------------------
    # ì§„í–‰ì¤‘ ê¸°ëŠ¥ ë°˜ì˜ í˜„í™© í‘œì‹œ
    # -----------------------------
    with st.expander("ğŸ› ï¸ í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ê¸°ëŠ¥ ë°˜ì˜ í˜„í™©"):
        st.markdown("""
        # ğŸ”§ ê¸°ëŠ¥ ë°˜ì˜ í˜„í™©

        **1. ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€**
        - ìƒë‹¨ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì¶”ì´ ì˜ì—­(ì—°ë„ ì„ íƒ, ê¸°ì¤€ë°°ì¶œëŸ‰, ê·¸ë˜í”„ 2ê°œ) ë ˆì´ì•„ì›ƒ ìœ ì§€

        **2. ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë¶„ì„(ì‹ ê·œ)**
        - ê³µë‹¨ ì „ì²´ ê¸°ì¤€(U/V/W ê¸°ë°˜)
        - ì†Œì†ê¸°êµ¬ë³„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë° ë¶„í¬/ì¦ê°ë¥  ë¶„ì„

        **3. ì—ë„ˆì§€ ê¸°ë°˜ í”¼ë“œë°±(ì‹ ê·œ)**
        - ê³µë‹¨ ì „ì²´: ê¸°ì¤€ ë‹¬ / ëª©í‘œë‹¬ì„±ì„ ìœ„í•œ ê°ì¶•ë¥  ë¶„ì„
        - ì†Œì†ê¸°êµ¬ë³„: ì‚¬ìš© ë¶„í¬ ìˆœìœ„ / 3ê°œë…„ í‰ê·  ì¦ê°€ ìˆœìœ„ /
          í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(ì—°ë©´ì  ê¸°ì¤€) ìˆœìœ„ / ëª©í‘œ ê¶Œì¥ ê°ì¶•ëŸ‰ / ì¦ê°€ ì‚¬ìœ  ì œì¶œ ì—¬ë¶€

        **4. ê³µí†µ**
        - ê¸°ê´€ ìˆœì„œ ê³ ì •
        - í‘œëŠ” í™”ë©´ ì „ì²´ í­ìœ¼ë¡œ ì¶œë ¥
        - None / NaNì€ '-'ë¡œ í‘œì‹œ
        """)

    # ------------------------------
    # íŒŒì¼ ì—…ë¡œë“œ
    # ------------------------------
    st.markdown("### ì›”ë³„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ íŒŒì¼ ì—…ë¡œë“œ")

    upload_col1, upload_col2 = st.columns([1.2, 2])
    new_file_processed = False

    with upload_col1:
        uploaded_files = st.file_uploader(
            "ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ê´€ë¦¬ .xlsx íŒŒì¼ ì—…ë¡œë“œ",
            type=["xlsx"],
            accept_multiple_files=True,
        )

        if uploaded_files:
            for f in uploaded_files:
                if f.name in st.session_state["processed_uploads"]:
                    continue
                try:
                    _, year, saved_path = loader.process_uploaded_energy_file(
                        file_obj=f,
                        original_filename=f.name,
                        base_dir=ENERGY_DIR,
                    )
                    st.session_state["processed_uploads"].add(f.name)
                    st.success(f"{f.name} ({year}) ì—…ë¡œë“œ ì™„ë£Œ")
                    new_file_processed = True
                except Exception as e:
                    st.error(f"ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")

        if new_file_processed:
            st.rerun()

    # ì €ì¥ëœ íŒŒì¼ ëª©ë¡
    with upload_col2:
        st.markdown("#### ì €ì¥ëœ íŒŒì¼ ëª©ë¡")

        df_all, files_meta, load_errors = load_all_energy_data()

        if files_meta:
            df_files = pd.DataFrame(files_meta).sort_values(
                ["ì—°ë„", "ì—…ë¡œë“œì‹œê°„"], ascending=[False, False]
            )
            st.table(df_files[["ì—°ë„", "íŒŒì¼ëª…", "ì—…ë¡œë“œì‹œê°„"]])
        else:
            st.info("ì €ì¥ëœ íŒŒì¼ ì—†ìŒ")

    st.markdown("---")

    if df_all is None:
        st.warning("ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # -----------------------------
    # analyzer ê¸°ë°˜ ì§‘ê³„ ë°ì´í„° íŒ¨í‚¤ì§€
    #  (ìƒë‹¨ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì¶”ì´ ì˜ì—­ ìš©)
    # -----------------------------
    datasets = analyzer.build_dashboard_datasets(df_all, baseline_map)
    annual_total = datasets["annual_total"]
    annual_total_with_baseline = datasets["annual_total_with_baseline"]
    monthly_total = datasets["monthly_total"]
    monthly_by_agency = datasets["monthly_by_agency"]
    annual_by_agency = datasets["annual_by_agency"]

    years = sorted(df_all["ì—°ë„"].dropna().unique().tolist())
    default_year = max(years)

    # ============================================================
    # 1) ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì¶”ì´ (ê¸°ì¡´ ìƒë‹¨ ì˜ì—­ ìœ ì§€)
    # ============================================================

    st.markdown("## ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì¶”ì´")

    filter_col, main_col = st.columns([1, 3])

    # ----- ì¢Œì¸¡ í•„í„° -----
    with filter_col:
        st.subheader("í•„í„°")

        view_scope = st.radio("ë³´ê¸° ë²”ìœ„", ["ê³µë‹¨ ì „ì²´", "ê¸°ê´€ë³„"], index=0)

        selected_year = st.selectbox(
            "ì´í–‰ì—°ë„ ì„ íƒ",
            years,
            index=years.index(default_year),
        )

        selected_org = None
        if view_scope == "ê¸°ê´€ë³„":
            org_list = df_all["ê¸°ê´€ëª…"].dropna().unique().tolist()
            ordered = [o for o in FACILITY_ORDER if o in org_list]
            others = sorted([o for o in org_list if o not in FACILITY_ORDER])
            org_options = ordered + others
            if not org_options:
                st.warning("ê¸°ê´€ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                selected_org = st.selectbox("ê¸°ê´€ ì„ íƒ", org_options)

        st.markdown("ì—ë„ˆì§€ ì¢…ë¥˜ í•„í„° (ì¶”í›„ í™•ì¥ìš©)")
        _ = st.selectbox("ì—ë„ˆì§€ ì¢…ë¥˜", ["ì „ì²´"])

    # ----- ìš°ì¸¡ ì£¼ìš”ì§€í‘œ + ê·¸ë˜í”„ -----
    with main_col:
        # ì„ íƒ ì—°ë„ ê¸°ì¤€ KPI (ê³µë‹¨ ì „ì²´ ê¸°ì¤€)
        kpi_row = annual_total_with_baseline[
            annual_total_with_baseline["ì—°ë„"] == selected_year
        ]

        if not kpi_row.empty:
            row0 = kpi_row.iloc[0]
            kpi_baseline = row0["ê¸°ì¤€ë°°ì¶œëŸ‰"]
            kpi_emission = row0["ì—°ê°„ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰"]
            kpi_ratio_pct = (
                row0["ë°°ì¶œë¹„ìœ¨"] * 100 if pd.notna(row0["ë°°ì¶œë¹„ìœ¨"]) else None
            )
            kpi_reduction_pct = row0["ê°ì¶•ë¥ (%)"]
        else:
            kpi_baseline = None
            kpi_emission = None
            kpi_ratio_pct = None
            kpi_reduction_pct = None

        k1, k2, k3, k4 = st.columns(4)

        # ì„ íƒ ì—°ë„ + ê¸°ì¤€ë°°ì¶œëŸ‰
        if kpi_baseline is not None:
            k1.metric("ì„ íƒ ì—°ë„", f"{selected_year}ë…„")
            k1.caption(f"ê¸°ì¤€ë°°ì¶œëŸ‰: {kpi_baseline:,.0f} tCO2eq")
        else:
            k1.metric("ì„ íƒ ì—°ë„", f"{selected_year}ë…„")
            k1.caption("ê¸°ì¤€ë°°ì¶œëŸ‰ ë¯¸ë“±ë¡")

        # ì—°ê°„ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰
        if kpi_emission is not None:
            k2.metric("ì—°ê°„ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰(ê³µë‹¨)", f"{kpi_emission:,.0f} tCO2eq")
        else:
            k2.metric("ì—°ê°„ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰(ê³µë‹¨)", "-")

        # ê°ì¶•ë¥ (ì „ì²´ ê¸°ì¤€)
        if kpi_reduction_pct is not None:
            k3.metric("ê°ì¶•ë¥ (ì „ì²´ ê¸°ì¤€)", f"{kpi_reduction_pct:,.1f} %")
        else:
            k3.metric("ê°ì¶•ë¥ (ì „ì²´ ê¸°ì¤€)", "-")

        # ê¸°ì¤€ë°°ì¶œëŸ‰ ëŒ€ë¹„ ë°°ì¶œë¹„ìœ¨
        if kpi_ratio_pct is not None:
            k4.metric("ê¸°ì¤€ë°°ì¶œëŸ‰ ëŒ€ë¹„ ë°°ì¶œë¹„ìœ¨", f"{kpi_ratio_pct:,.1f} %")
        else:
            k4.metric("ê¸°ì¤€ë°°ì¶œëŸ‰ ëŒ€ë¹„ ë°°ì¶œë¹„ìœ¨", "-")

        # ê·¸ë˜í”„ìš© ë°ì´í„°
        if view_scope == "ê³µë‹¨ ì „ì²´":
            monthly_df = monthly_total[monthly_total["ì—°ë„"] == selected_year]
            recent_df, _ = analyzer.get_recent_years_ghg(
                annual_total, base_year=int(selected_year)
            )
        else:
            if selected_org is not None:
                monthly_df = monthly_by_agency[
                    (monthly_by_agency["ì—°ë„"] == selected_year)
                    & (monthly_by_agency["ê¸°ê´€ëª…"] == selected_org)
                ]
                annual_sel = annual_by_agency[
                    annual_by_agency["ê¸°ê´€ëª…"] == selected_org
                ]
                recent_df, _ = analyzer.get_recent_years_ghg(
                    annual_sel, base_year=int(selected_year)
                )
            else:
                monthly_df = pd.DataFrame()
                recent_df = pd.DataFrame()

        # ê·¸ë˜í”„ 2ê°œ ì¢Œìš° ë°°ì¹˜
        st.markdown("")

        c1, c2 = st.columns(2)

        with c1:
            st.markdown("#### ì´í–‰ì—°ë„ ì›”ë³„ ì˜¨ì‹¤ê°€ìŠ¤ ì¶”ì´")
            if not monthly_df.empty:
                chart_month = (
                    monthly_df.sort_values("ì›”")[["ì›”", "ì›”ë³„ ì˜¨ì‹¤ê°€ìŠ¤ í™˜ì‚°ëŸ‰"]]
                    .set_index("ì›”")
                )
                st.line_chart(chart_month)
            else:
                st.info("ì„ íƒ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ì›”ë³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        with c2:
            st.markdown("#### ìµœê·¼ 5ê°œë…„ ì—°ê°„ ë°°ì¶œëŸ‰ ì¶”ì´")
            if not recent_df.empty:
                chart_recent = (
                    recent_df.sort_values("ì—°ë„")[["ì—°ë„", "ì—°ê°„ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰"]]
                    .set_index("ì—°ë„")
                )
                st.bar_chart(chart_recent)
            else:
                st.info("ì„ íƒ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ì—°ê°„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ============================================================
    # 2) ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë¶„ì„ (ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ê´€ë¦¬ ì—‘ì…€ ê¸°ì¤€)
    # ============================================================

    st.markdown("---")
    st.markdown("## ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë¶„ì„")

    raw_df_original = load_raw_year_data(int(selected_year))
    if raw_df_original is None:
        st.error(f"{selected_year}ë…„ ì›ë³¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # U/V/W & ê¸°ê´€ëª… ì „ì²˜ë¦¬ (ë°ì´í„° ì •ì œ + ì˜¤ë¥˜ ë¡œê¹…)
    raw_df, org_col, U_col, V_col, W_col, preprocess_errors = preprocess_uv_w(
        raw_df_original
    )

    # --- 3-1) ê³µë‹¨ ì „ì²´ ê¸°ì¤€ ---

    # ê³µë‹¨ ì „ì²´ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ / ë©´ì ë‹¹ ë°°ì¶œëŸ‰
    total_U = raw_df[U_col].sum(skipna=True)
    total_V = raw_df[V_col].sum(skipna=True)

    # 3ê°œë…„ í‰ê·  ëŒ€ë¹„ ì¦ê°ë¥  (Uì—´ ê¸°ì¤€)
    past_years = [
        int(selected_year) - 3,
        int(selected_year) - 2,
        int(selected_year) - 1,
    ]
    past_u_values: List[float] = []

    for y in past_years:
        df_past_raw = load_raw_year_data(y)
        if df_past_raw is not None:
            df_past, p_org, p_U, p_V, p_W, err = preprocess_uv_w(df_past_raw)
            val = df_past[p_U].sum(skipna=True)
            past_u_values.append(val)

    if past_u_values:
        past_avg_U = sum(past_u_values) / len(past_u_values)
        U_change_rate = (
            (total_U - past_avg_U) / past_avg_U * 100 if past_avg_U else None
        )
    else:
        past_avg_U = None
        U_change_rate = None

    st.markdown("### ê³µë‹¨ ì „ì²´ ê¸°ì¤€")

    k1, k2, k3 = st.columns(3)
    k1.metric("ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(í˜„ì¬ ê¸°ì¤€)", f"{total_U:,.0f}")
    k2.metric("ë©´ì ë‹¹ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰", f"{total_V:,.0f}")
    k3.metric(
        "3ê°œë…„ í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ëŒ€ë¹„ ì¦ê°ë¥ ",
        "-" if U_change_rate is None else f"{U_change_rate:,.1f} %",
    )

    # í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(ì—°ë©´ì  ê¸°ì¤€, Wì—´ ê¸°ì¤€)
    st.markdown("#### í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(ì—°ë©´ì  ê¸°ì¤€)")

    def avg_group(names: List[str]) -> float | None:
        df_tmp = raw_df[raw_df[org_col].isin(names)]
        if df_tmp.empty:
            return None
        return float(df_tmp[W_col].mean(skipna=True))

    g1, g2, g3 = st.columns(3)
    med_avg = avg_group(MEDICAL_FACILITIES)
    wel_avg = avg_group(WELFARE_FACILITIES)
    oth_avg = avg_group(OTHER_FACILITIES)

    g1.metric(
        "ì˜ë£Œì‹œì„¤",
        "-" if med_avg is None else f"{med_avg:,.1f}",
    )
    g2.metric(
        "ë³µì§€ì‹œì„¤",
        "-" if wel_avg is None else f"{wel_avg:,.1f}",
    )
    g3.metric(
        "ê¸°íƒ€ì‹œì„¤",
        "-" if oth_avg is None else f"{oth_avg:,.1f}",
    )

    # --- 3-2) ì†Œì†ê¸°êµ¬ë³„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë¶„ì„ í‘œ ---

    st.markdown("### ì†Œì†ê¸°êµ¬ë³„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë¶„ì„ í‘œ")

    df_group = (
        raw_df.groupby(org_col)
        .agg(
            ì—ë„ˆì§€ì‚¬ìš©ëŸ‰=(U_col, "sum"),
            ë©´ì ë‹¹ë°°ì¶œëŸ‰=(V_col, "sum"),
            Wí‰ê· =(W_col, "mean"),
        )
        .reset_index()
    )

    # ì»¬ëŸ¼ ì´ë¦„/ë‚´ìš©ì„ ì‚¬ì–‘ì— ë§ê²Œ êµ¬ì„±
    df_group = df_group.rename(columns={
        org_col: "êµ¬ë¶„",
        "ì—ë„ˆì§€ì‚¬ìš©ëŸ‰": "ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(í˜„ì¬ ê¸°ì¤€)",
        "ë©´ì ë‹¹ë°°ì¶œëŸ‰": "ë©´ì ë‹¹ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰",
    })

    # ì‹œì„¤êµ¬ë¶„
    def facility_type(name: str) -> str:
        if name in MEDICAL_FACILITIES:
            return "ì˜ë£Œì‹œì„¤"
        if name in WELFARE_FACILITIES:
            return "ë³µì§€ì‹œì„¤"
        if name in OTHER_FACILITIES:
            return "ê¸°íƒ€ì‹œì„¤"
        return "ê¸°íƒ€ì‹œì„¤"

    df_group["ì‹œì„¤êµ¬ë¶„"] = df_group["êµ¬ë¶„"].apply(facility_type)

    # ê³µë‹¨ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë¶„í¬ ë¹„ìœ¨
    df_group["ê³µë‹¨ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë¶„í¬ ë¹„ìœ¨"] = (
        df_group["ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(í˜„ì¬ ê¸°ì¤€)"] / total_U * 100 if total_U else pd.NA
    )

    # ì‹œì„¤êµ°ë³„ í‰ê·  ëŒ€ë¹„ ì‚¬ìš©ë¹„ìœ¨
    def avg_compare(row):
        if row["ì‹œì„¤êµ¬ë¶„"] == "ì˜ë£Œì‹œì„¤":
            return (
                row["Wí‰ê· "] / med_avg if (med_avg is not None and med_avg != 0) else pd.NA
            )
        if row["ì‹œì„¤êµ¬ë¶„"] == "ë³µì§€ì‹œì„¤":
            return (
                row["Wí‰ê· "] / wel_avg if (wel_avg is not None and wel_avg != 0) else pd.NA
            )
        return (
            row["Wí‰ê· "] / oth_avg if (oth_avg is not None and oth_avg != 0) else pd.NA
        )

    df_group["í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(ì—°ë©´ì  ê¸°ì¤€) ëŒ€ë¹„ ì‚¬ìš©ë¹„ìœ¨"] = df_group.apply(
        avg_compare, axis=1
    )

    # 3ê°œë…„ í‰ê·  ì—ë„ˆì§€ ì‚¬ìš© ì¦ê°ë¥  (ê¸°ê´€ë³„)
    def three_year_rate(name: str):
        vals: List[float] = []
        for y in past_years:
            dfp_raw = load_raw_year_data(y)
            if dfp_raw is not None:
                dfp, p_org, p_U, p_V, p_W, err = preprocess_uv_w(dfp_raw)
                dfp = dfp[dfp[p_org].notna()].copy()
                dfp[p_org] = dfp[p_org].astype(str).str.strip()
                now_val = dfp[dfp[p_org] == name][p_U].sum(skipna=True)
                vals.append(float(now_val))

        if vals:
            avg_past = sum(vals) / len(vals)
            now_u = df_group[df_group["êµ¬ë¶„"] == name]["ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(í˜„ì¬ ê¸°ì¤€)"]
            if not now_u.empty and avg_past > 0:
                return (now_u.iloc[0] - avg_past) / avg_past * 100
        return pd.NA

    df_group["3ê°œë…„ í‰ê·  ì—ë„ˆì§€ ì‚¬ìš© ì¦ê°ë¥ "] = df_group["êµ¬ë¶„"].apply(three_year_rate)

    # ê¸°ê´€ ìˆœì„œ ê³ ì •
    df_group["êµ¬ë¶„"] = pd.Categorical(
        df_group["êµ¬ë¶„"], categories=FACILITY_ORDER, ordered=True
    )
    df_group = df_group.sort_values("êµ¬ë¶„")

    # NaNì€ '-'ë¡œ í‘œì‹œí•˜ë©´ì„œ ì „ì²´í­ìœ¼ë¡œ í‘œì‹œ
    st.dataframe(
        df_group.style.format(na_rep="-"),
        use_container_width=True,
    )

    # ============================================================
    # 3) ì—ë„ˆì§€ ê¸°ë°˜ í”¼ë“œë°±
    # ============================================================

    st.markdown("## í”¼ë“œë°±")

    # --- 4-1) ê³µë‹¨ ì „ì²´ ê¸°ì¤€ ---

    st.markdown("### ê³µë‹¨ ì „ì²´ ê¸°ì¤€")

    # ê¸°ì¤€ ë‹¬: ì›ë³¸ ì—‘ì…€ì—ì„œ ì‹¤ì œ ê°’ì´ ìˆëŠ” ë§ˆì§€ë§‰ ì›”
    ê¸°ì¤€ë‹¬ = detect_last_month_with_data(raw_df_original)

    baseline_val = baseline_map.get(int(selected_year))
    reduction_ratio = (
        total_V / baseline_val * 100 if (baseline_val and baseline_val != 0) else None
    )

    f1, f2 = st.columns(2)
    f1.metric("ê¸°ì¤€ ë‹¬", f"{ê¸°ì¤€ë‹¬}ì›”" if ê¸°ì¤€ë‹¬ is not None else "-")
    f2.metric(
        "ëª©í‘œë‹¬ì„±ì„ ìœ„í•œ ê°ì¶•ë¥  ë¶„ì„",
        "-" if reduction_ratio is None else f"{reduction_ratio:,.1f} %",
    )

    # --- 4-2) ì†Œì†ê¸°êµ¬ë³„ í”¼ë“œë°± í‘œ ---

    st.markdown("### ì†Œì†ê¸°êµ¬ë³„ í”¼ë“œë°± í‘œ")

    df_fb = df_group.copy()

    # ì‚¬ìš© ë¶„í¬ ìˆœìœ„ (ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ / ê³µë‹¨ ì „ì²´ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ê¸°ì¤€)
    df_fb["ì‚¬ìš© ë¶„í¬ ìˆœìœ„"] = df_fb["ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(í˜„ì¬ ê¸°ì¤€)"].rank(
        ascending=False, method="dense"
    )

    # 3ê°œë…„ í‰ê·  ì¦ê°€ ìˆœìœ„
    df_fb["3ê°œë…„ í‰ê·  ì¦ê°€ ìˆœìœ„"] = df_fb["3ê°œë…„ í‰ê·  ì—ë„ˆì§€ ì‚¬ìš© ì¦ê°ë¥ "].rank(
        ascending=False, method="dense"
    )

    # í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(ì—°ë©´ì  ê¸°ì¤€) ìˆœìœ„
    df_fb["í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(ì—°ë©´ì  ê¸°ì¤€) ìˆœìœ„"] = df_fb[
        "í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(ì—°ë©´ì  ê¸°ì¤€) ëŒ€ë¹„ ì‚¬ìš©ë¹„ìœ¨"
    ].rank(ascending=False, method="dense")

    # ëª©í‘œ ê¶Œì¥ ê°ì¶•ëŸ‰ (ê³µë‹¨ ì „ì²´ ì¶”ê°€ ê°ì¶• í•„ìš”ëŸ‰ì„ ê¸°ê´€ë³„ ë¹„ì¤‘ìœ¼ë¡œ ë°°ë¶„)
    if baseline_val and baseline_val > 0 and total_U > 0:
        need_total = total_V - baseline_val
        if need_total < 0:
            need_total = 0
        df_fb["ëª©í‘œ ê¶Œì¥ ê°ì¶•ëŸ‰"] = need_total * (
            df_fb["ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(í˜„ì¬ ê¸°ì¤€)"] / total_U
        )
    else:
        df_fb["ëª©í‘œ ê¶Œì¥ ê°ì¶•ëŸ‰"] = pd.NA

    # ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì¦ê°€ ì‚¬ìœ  ì œì¶œ ëŒ€ìƒ
    def need_reason(row):
        cond1 = (
            pd.notna(row["3ê°œë…„ í‰ê·  ì—ë„ˆì§€ ì‚¬ìš© ì¦ê°ë¥ "])
            and row["3ê°œë…„ í‰ê·  ì—ë„ˆì§€ ì‚¬ìš© ì¦ê°ë¥ "] > 0
        )
        cond2 = (
            pd.notna(row["í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(ì—°ë©´ì  ê¸°ì¤€) ëŒ€ë¹„ ì‚¬ìš©ë¹„ìœ¨"])
            and row["í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(ì—°ë©´ì  ê¸°ì¤€) ëŒ€ë¹„ ì‚¬ìš©ë¹„ìœ¨"] > 1
        )
        return "O" if (cond1 and cond2) else "X"

    df_fb["ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì¦ê°€ ì‚¬ìœ  ì œì¶œ ëŒ€ìƒ"] = df_fb.apply(need_reason, axis=1)

    # í”¼ë“œë°± í‘œ ì¶œë ¥ (ì „ì²´ í­, NaN â†’ '-')
    st.dataframe(
        df_fb[
            [
                "êµ¬ë¶„",
                "ì‚¬ìš© ë¶„í¬ ìˆœìœ„",
                "3ê°œë…„ í‰ê·  ì¦ê°€ ìˆœìœ„",
                "í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(ì—°ë©´ì  ê¸°ì¤€) ìˆœìœ„",
                "ëª©í‘œ ê¶Œì¥ ê°ì¶•ëŸ‰",
                "ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì¦ê°€ ì‚¬ìœ  ì œì¶œ ëŒ€ìƒ",
            ]
        ].style.format(na_rep="-"),
        use_container_width=True,
    )

    # ============================================================
    # 4) ê³µë‹¨ ì „ì²´ ë¶„ì„Â·ì½”ë©˜íŠ¸ (ê¸°ì¡´ ìœ ì§€)
    # ============================================================

    st.markdown("## ê³µë‹¨ ì „ì²´ ë¶„ì„Â·ì½”ë©˜íŠ¸")

    annual_total_only = analyzer.get_annual_ghg(df_all, by_agency=False)
    actual_emission = annual_total_only.query(
        "ì—°ë„ == @selected_year"
    )["ì—°ê°„ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰"].sum()

    recent_total_df, _ = analyzer.get_recent_years_ghg(
        annual_total_only,
        base_year=int(selected_year),
    )

    fb_text = feedback.generate_overall_feedback(
        year=int(selected_year),
        actual_emission=actual_emission,
        baseline_emission=baseline_val,
        reduction_rate_pct=None,
        ratio_to_baseline=None,
        recent_total_df=recent_total_df,
        current_month=ê¸°ì¤€ë‹¬,
    )

    st.write(fb_text)


# ============================================================
# âš™ï¸ 2) ê¸°ì¤€ë°°ì¶œëŸ‰ ê´€ë¦¬ íƒ­
# ============================================================

with tab_baseline:
    st.header("ê¸°ì¤€ë°°ì¶œëŸ‰ ê´€ë¦¬")

    st.markdown("### í˜„ì¬ ê¸°ì¤€ë°°ì¶œëŸ‰ ëª©ë¡")
    df_b = pd.DataFrame(baseline_records)
    if not df_b.empty:
        st.table(df_b)
    else:
        st.info("ë“±ë¡ëœ ê¸°ì¤€ë°°ì¶œëŸ‰ ì—†ìŒ")

    st.markdown("### ê¸°ì¤€ë°°ì¶œëŸ‰ ì‹ ê·œ ë“±ë¡")
    col1, col2 = st.columns(2)

    new_year = col1.number_input("ì—°ë„", min_value=2000, max_value=2100, step=1)
    new_val = col2.number_input("ê¸°ì¤€ë°°ì¶œëŸ‰(tCO2eq)", min_value=0.0, step=100.0)

    if st.button("ì €ì¥"):
        baseline_mod.update_baseline_record(BASELINE_PATH, new_year, new_val)
        st.success("ê¸°ì¤€ë°°ì¶œëŸ‰ ì €ì¥ ì™„ë£Œ")
        st.rerun()


# ============================================================
# ğŸ”§ 3) ë””ë²„ê·¸ / ì§„ë‹¨ íƒ­
# ============================================================

with tab_debug:

    st.header("ë””ë²„ê·¸ / êµ¬ì¡° ì§„ë‹¨")

    st.markdown("### íŒŒì¼ êµ¬ì¡° ì§„ë‹¨")
    uploaded_debug_file = st.file_uploader("ì—‘ì…€ êµ¬ì¡° ì§„ë‹¨ íŒŒì¼ ì—…ë¡œë“œ (.xlsx)", type=["xlsx"])
    if uploaded_debug_file:
        from tempfile import NamedTemporaryFile

        with NamedTemporaryFile(delete=False, suffix=".xlsx") as tmp:
            tmp.write(uploaded_debug_file.read())
            tmp_path = Path(tmp.name)

        try:
            res = loader.validate_excel_file(tmp_path)
            st.json(res)
        except Exception as e:
            st.error(f"ì§„ë‹¨ ì˜¤ë¥˜: {e}")

    st.markdown("---")

    # ì‹¤í–‰ í™˜ê²½ ì§„ë‹¨ â€” loader.py í™•ì¸
    with st.expander("ğŸ§ª ì‹¤í–‰ í™˜ê²½ ì§„ë‹¨: loader.py í™•ì¸"):
        import modules.loader as ld
        import inspect

        st.subheader("ğŸ“Œ Streamlitì´ ì‚¬ìš© ì¤‘ì¸ loader.py ê²½ë¡œ")
        st.code(ld.__file__)

        st.subheader("ğŸ“Œ í•¨ìˆ˜ ëª©ë¡")
        st.write(dir(ld))

        st.subheader("ğŸ“Œ ì‹¤ì œ loader.py ì†ŒìŠ¤ ì½”ë“œ")
        try:
            st.code(inspect.getsource(ld), language="python")
        except Exception:
            st.error("ì†ŒìŠ¤ ì½”ë“œë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
