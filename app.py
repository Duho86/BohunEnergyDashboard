# app.py
# -*- coding: utf-8 -*-

from __future__ import annotations

from datetime import datetime
from pathlib import Path
import traceback

import pandas as pd
import streamlit as st

from modules import loader, analyzer, feedback, baseline as baseline_mod

# ============================
# ê¸°ë³¸ ì„¤ì •
# ============================

st.set_page_config(
    page_title="ê³µë‹¨ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ Â· ì˜¨ì‹¤ê°€ìŠ¤ ê´€ë¦¬ ëŒ€ì‹œë³´ë“œ",
    layout="wide",
)

st.title("ê³µë‹¨ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ Â· ì˜¨ì‹¤ê°€ìŠ¤ ê´€ë¦¬ ëŒ€ì‹œë³´ë“œ")

DATA_DIR = Path("data")
ENERGY_DIR = DATA_DIR / "energy"
BASELINE_PATH = DATA_DIR / "baseline.json"

def ensure_dirs():
    DATA_DIR.mkdir(parents=True, exist_ok=True)
    loader.ensure_energy_dir(ENERGY_DIR)

# ============================
# ë°ì´í„° ë¡œë”© í—¬í¼
# ============================

def load_all_energy_data(base_dir: Path = ENERGY_DIR):
    ensure_dirs()
    dfs = []
    meta_list = []
    errors = []

    for xlsx_path in sorted(base_dir.glob("*.xlsx")):
        try:
            df_std, year = loader.load_energy_xlsx(xlsx_path)
            dfs.append(df_std)

            stat = xlsx_path.stat()
            meta_list.append(
                {
                    "ì—°ë„": year,
                    "íŒŒì¼ëª…": xlsx_path.name,
                    "ê²½ë¡œ": str(xlsx_path),
                    "ì—…ë¡œë“œì‹œê°„": datetime.fromtimestamp(stat.st_mtime).strftime(
                        "%Y-%m-%d %H:%M:%S"
                    ),
                }
            )
        except loader.EnergyDataError as e:
            errors.append({"íŒŒì¼ëª…": xlsx_path.name, "ì—ëŸ¬": str(e)})
        except Exception as e:
            errors.append({"íŒŒì¼ëª…": xlsx_path.name, "ì—ëŸ¬": f"ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}"})

    df_all = pd.concat(dfs, ignore_index=True) if dfs else None
    return df_all, meta_list, errors

# ======================================
# ì›ë³¸ ì—ë„ˆì§€ íŒŒì¼(U/V/W) ë¡œë”© (ì‹ ê·œ)
# ======================================
def load_raw_year_data(year: int):
    """í•´ë‹¹ ì—°ë„ì˜ ì›ë³¸ ì—ë„ˆì§€ì‚¬ìš©ëŸ‰ê´€ë¦¬.xlsxë¥¼ ì›ë³¸ êµ¬ì¡°ë¡œ ë¡œë“œ."""
    for p in ENERGY_DIR.glob("*.xlsx"):
        if str(year) in p.name:
            return loader.load_energy_raw_for_analysis(p)
    return None  # íŒŒì¼ ì—†ìŒ

# ============================
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ============================

if "processed_uploads" not in st.session_state:
    st.session_state["processed_uploads"] = set()

ensure_dirs()

baseline_records = baseline_mod.load_baseline_records(BASELINE_PATH)
baseline_map = baseline_mod.get_baseline_map(baseline_records)

# ============================
# í™”ë©´ íƒ­ êµ¬ì„±
# ============================

tab_dashboard, tab_baseline, tab_debug = st.tabs(
    ["ğŸ“Š ëŒ€ì‹œë³´ë“œ", "âš™ï¸ ê¸°ì¤€ë°°ì¶œëŸ‰ ê´€ë¦¬", "ğŸ”§ ë””ë²„ê·¸/ì§„ë‹¨"]
)

# ============================================================
# ğŸ“Š 1) ëŒ€ì‹œë³´ë“œ íƒ­
# ============================================================

with tab_dashboard:

    # -----------------------------
    # ğŸ”§ ê°œë°œ ì§„í–‰ ìƒí™© í‘œì‹œ (ìš”ì²­ì‚¬í•­)
    # -----------------------------
    with st.expander("ğŸ› ï¸ í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ê¸°ëŠ¥ ë°˜ì˜ í˜„í™© (ì •ë³´ í‘œì‹œìš©)"):
        st.markdown("""
        # ğŸ”§ ê¸°ëŠ¥ ë°˜ì˜ í˜„í™© ìš”ì•½

        ## 1. ê¸°ì¡´ ê¸°ëŠ¥ ë³€ê²½
        - ê¸°ì¡´ **ì „ë§ë¶„ì„ ì„¹ì…˜ ì „ì²´ ì‚­ì œ**
        - ê¸°ì¡´ **í”¼ë“œë°± ì„¹ì…˜ ì‚­ì œ**, ë‹¨  
          â†’ ë§ˆì§€ë§‰ "**ê³µë‹¨ ì „ì²´ ë¶„ì„Â·ì½”ë©˜íŠ¸**"ëŠ” ìœ ì§€ë¨

        ## 2. ì‹ ê·œ ê¸°ëŠ¥ â€“ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë¶„ì„ (U/V/W ê¸°ë°˜)
        - ê³µë‹¨ ì „ì²´ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(Uì—´ í•©ê³„)
        - ë©´ì ë‹¹ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰(Vì—´ í•©ê³„)
        - 3ê°œë…„ í‰ê·  ëŒ€ë¹„ ì¦ê°ë¥  (ë¹„êµ ë¶ˆê°€ ì²˜ë¦¬)
        - ì‹œì„¤êµ°ë³„(Wì—´ í‰ê· ) ë¶„ì„ (ì˜ë£Œ / ë³µì§€ / ê¸°íƒ€)
        - ì†Œì†ê¸°êµ¬ë³„ ì—ë„ˆì§€ ì‚¬ìš© ë¶„ì„(ë¶„í¬ ë¹„ìœ¨, í‰ê·  ëŒ€ë¹„ ë¹„ìœ¨, ì¦ê°€ìœ¨ ë“±)

        ## 3. ì—ë„ˆì§€ ê¸°ë°˜ í”¼ë“œë°±
        - ê³µë‹¨ ì „ì²´: í˜„ì¬ ì›” / ëª©í‘œë‹¬ì„±ì„ ìœ„í•œ ê°ì¶•ë¥ 
        - ì†Œì†ê¸°êµ¬ë³„: ì‚¬ìš© ë¶„í¬ ìˆœìœ„ / 3ê°œë…„ ì¦ê°€ìœ¨ ìˆœìœ„ / í‰ê·  ëŒ€ë¹„ ì‚¬ìš©ë¹„ìœ¨ ìˆœìœ„ /
          ê¶Œì¥ ê°ì¶•ëŸ‰ / ì¦ê°€ ì‚¬ìœ  ì œì¶œ ëŒ€ìƒ

        ## 4. ê³µí†µ ê¸°ëŠ¥
        - ê¸°ê´€ ìˆœì„œ ê³ ì • ì •ë ¬ ì ìš©
        - ëª¨ë“  í‘œ ì „ì²´í­ ë°°ì¹˜ (ì¢Œìš° ë¶„í•  ì œê±°)

        """)

    # ------------------------------
    # íŒŒì¼ ì—…ë¡œë“œ
    # ------------------------------
    st.markdown("### ì›”ë³„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ íŒŒì¼ ì—…ë¡œë“œ")

    upload_col1, upload_col2 = st.columns([1.2, 2])
    new_file_processed = False

    with upload_col1:
        uploaded_files = st.file_uploader(
            "ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ê´€ë¦¬ .xlsx íŒŒì¼ ì—…ë¡œë“œ",
            type=["xlsx"],
            accept_multiple_files=True,
            help="ì˜ˆ: 2024ë…„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ê´€ë¦¬.xlsx",
        )
        st.caption("â€» ì—…ë¡œë“œ ì‹œ data/energy/ í´ë”ì— ì €ì¥ë˜ê³ , ëŒ€ì‹œë³´ë“œê°€ ìë™ ê°±ì‹ ë©ë‹ˆë‹¤.")

        if uploaded_files:
            for f in uploaded_files:
                if f.name in st.session_state["processed_uploads"]:
                    continue
                try:
                    _, year, saved_path = loader.process_uploaded_energy_file(
                        file_obj=f,
                        original_filename=f.name,
                        base_dir=ENERGY_DIR,
                    )
                    st.session_state["processed_uploads"].add(f.name)
                    st.success(f"{f.name} (ì—°ë„ {year}) ì—…ë¡œë“œ ì™„ë£Œ")
                    new_file_processed = True

                except Exception as e:
                    st.error(f"{f.name} ì—…ë¡œë“œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

        if new_file_processed:
            st.rerun()

    with upload_col2:
        st.markdown("#### ì €ì¥ëœ ì—°ë„ë³„ íŒŒì¼ ëª©ë¡")

        df_all, files_meta, load_errors = load_all_energy_data()
        if files_meta:
            df_files = pd.DataFrame(files_meta).sort_values(
                ["ì—°ë„", "ì—…ë¡œë“œì‹œê°„"], ascending=[False, False]
            )
            st.table(df_files[["ì—°ë„", "íŒŒì¼ëª…", "ì—…ë¡œë“œì‹œê°„"]])
        else:
            st.info("ì €ì¥ëœ íŒŒì¼ ì—†ìŒ")

    st.markdown("---")

    if df_all is None:
        st.warning("ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # -----------------------------
    # ì§‘ê³„ ê³„ì‚° (ì˜¨ì‹¤ê°€ìŠ¤ KPI ì „ìš©)
    # -----------------------------
    datasets = analyzer.build_dashboard_datasets(df_all, baseline_map)

    # -----------------------------
    # í•„í„°
    # -----------------------------
    years = sorted(df_all["ì—°ë„"].unique().tolist())
    selected_year = max(years)

    st.sidebar.header("í•„í„°")
    st.sidebar.markdown("**ê¸°ê´€ ì„ íƒ ì œê±°ë¨ â†’ ê³µë‹¨ ì „ì²´ ê¸°ì¤€ ê³ ì •**")

    selected_year = st.sidebar.selectbox("ì—°ë„ ì„ íƒ", years, index=years.index(selected_year))

    # ============================
    # ğŸ”¥ ì‹ ê·œ ê¸°ëŠ¥ 1 â€” ì£¼ìš”ì§€í‘œ
    # ============================

    st.markdown("## ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì¶”ì´")

    raw_df = load_raw_year_data(selected_year)
    if raw_df is None:
        st.error(f"{selected_year}ë…„ ì›ë³¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # ì›ë³¸ ì»¬ëŸ¼ ì°¸ì¡°
    org_col = raw_df.columns[2]   # Cì—´
    U_col   = raw_df.columns[20]  # Uì—´
    V_col   = raw_df.columns[21]  # Vì—´
    W_col   = raw_df.columns[22]  # Wì—´

    # ê³µë‹¨ ì „ì²´ U/V/W ê³„ì‚°
    total_U = raw_df[U_col].sum(skipna=True)
    total_V = raw_df[V_col].sum(skipna=True)

    # 3ê°œë…„ í‰ê·  U ê³„ì‚°
    past_years = [selected_year-3, selected_year-2, selected_year-1]
    past_vals = []
    for y in past_years:
        df_past = load_raw_year_data(y)
        if df_past is not None:
            past_vals.append(df_past[df_past.columns[20]].sum(skipna=True))

    if len(past_vals) >= 1:
        past_avg = sum(past_vals)/len(past_vals)
        U_change_rate = (total_U - past_avg) / past_avg * 100 if past_avg else None
    else:
        past_avg = None
        U_change_rate = None  # ë¹„êµë¶ˆê°€

    k1, k2, k3 = st.columns(3)
    k1.metric("ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(Uí•©ê³„)", f"{total_U:,.0f}")
    k2.metric("ë©´ì ë‹¹ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰(Ví•©ê³„)", f"{total_V:,.0f}")
    k3.metric("3ê°œë…„ í‰ê·  ëŒ€ë¹„ ì¦ê°ë¥ ", "-" if U_change_rate is None else f"{U_change_rate:,.1f}%")

    # ============================
    # ì‹ ê·œ ê¸°ëŠ¥ 2 â€” ì‹œì„¤êµ°ë³„ í‰ê· (Wì—´)
    # ============================

    st.markdown("### ì‹œì„¤êµ°ë³„ í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(Wì—´ ê¸°ì¤€)")

    MEDICAL = ["ì¤‘ì•™ë³‘ì›", "ë¶€ì‚°ë³‘ì›", "ê´‘ì£¼ë³‘ì›", "ëŒ€êµ¬ë³‘ì›", "ëŒ€ì „ë³‘ì›", "ì¸ì²œë³‘ì›"]
    WELFARE = ["ìˆ˜ì›ìš”ì–‘ì›","ê´‘ì£¼ìš”ì–‘ì›","ê¹€í•´ìš”ì–‘ì›","ëŒ€êµ¬ìš”ì–‘ì›","ëŒ€ì „ìš”ì–‘ì›","ë‚¨ì–‘ì£¼ìš”ì–‘ì›","ì›ì£¼ìš”ì–‘ì›","ì „ì£¼ìš”ì–‘ì›"]
    OTHER   = ["ë³¸ì‚¬","êµìœ¡ì—°êµ¬ì›","ë³´í›ˆì›","ì¬í™œì²´ìœ¡ì„¼í„°","íœ´ì–‘ì›"]

    def avg_group(names):
        return raw_df[raw_df[org_col].isin(names)][W_col].mean()

    wg1, wg2, wg3 = st.columns(3)
    wg1.metric("ì˜ë£Œì‹œì„¤ í‰ê· (W)", f"{avg_group(MEDICAL):,.1f}")
    wg2.metric("ë³µì§€ì‹œì„¤ í‰ê· (W)", f"{avg_group(WELFARE):,.1f}")
    wg3.metric("ê¸°íƒ€ì‹œì„¤ í‰ê· (W)", f"{avg_group(OTHER):,.1f}")

    # ============================
    # ì‹ ê·œ ê¸°ëŠ¥ 3 â€” ì†Œì†ê¸°êµ¬ë³„ ë¶„ì„ í‘œ
    # ============================

    st.markdown("## ì†Œì†ê¸°êµ¬ë³„ ì—ë„ˆì§€ ì‚¬ìš© ë¶„ì„")

    df_group = raw_df.groupby(org_col).agg(
        Uí•©ê³„=(U_col, "sum"),
        Ví•©ê³„=(V_col, "sum"),
        Wí‰ê· =(W_col, "mean"),
    ).reset_index().rename(columns={org_col: "ê¸°ê´€ëª…"})

    # ì‹œì„¤êµ¬ë¶„
    def facility_type(name):
        if name in MEDICAL: return "ì˜ë£Œì‹œì„¤"
        if name in WELFARE: return "ë³µì§€ì‹œì„¤"
        if name in OTHER:   return "ê¸°íƒ€ì‹œì„¤"
        return "ê¸°íƒ€ì‹œì„¤"

    df_group["ì‹œì„¤êµ¬ë¶„"] = df_group["ê¸°ê´€ëª…"].apply(facility_type)

    # ê³µë‹¨ ì „ì²´ ëŒ€ë¹„ ë¶„í¬ë¹„ìœ¨
    df_group["ë¶„í¬ë¹„ìœ¨"] = df_group["Uí•©ê³„"] / total_U * 100 if total_U else None

    # ì‹œì„¤êµ°ë³„ í‰ê·  ëŒ€ë¹„ ë¹„ìœ¨
    med_avg = avg_group(MEDICAL)
    wel_avg = avg_group(WELFARE)
    oth_avg = avg_group(OTHER)

    def avg_compare(row):
        if row["ì‹œì„¤êµ¬ë¶„"]=="ì˜ë£Œì‹œì„¤":
            return row["Wí‰ê· "]/med_avg if med_avg else None
        elif row["ì‹œì„¤êµ¬ë¶„"]=="ë³µì§€ì‹œì„¤":
            return row["Wí‰ê· "]/wel_avg if wel_avg else None
        else:
            return row["Wí‰ê· "]/oth_avg if oth_avg else None

    df_group["í‰ê· ëŒ€ë¹„ì‚¬ìš©ë¹„ìœ¨"] = df_group.apply(avg_compare, axis=1)

    # 3ê°œë…„ í‰ê·  ëŒ€ë¹„ ì¦ê°ë¥ 
    def three_year_rate(name):
        past_vals=[]
        for y in past_years:
            dfp = load_raw_year_data(y)
            if dfp is not None:
                val = dfp[dfp[dfp.columns[2]]==name][dfp.columns[20]].sum()
                past_vals.append(val)
        if len(past_vals)>=1:
            avg_p = sum(past_vals)/len(past_vals)
            if avg_p==0: return None
            now = df_group[df_group["ê¸°ê´€ëª…"]==name]["Uí•©ê³„"].iloc[0]
            return (now-avg_p)/avg_p*100
        return None

    df_group["3ê°œë…„ì¦ê°ë¥ "] = df_group["ê¸°ê´€ëª…"].apply(three_year_rate)

    # ê¸°ê´€ ì¶œë ¥ ìˆœì„œ ì ìš©
    ORDER = ["ë³¸ì‚¬","ì¤‘ì•™ë³‘ì›","ë¶€ì‚°ë³‘ì›","ê´‘ì£¼ë³‘ì›","ëŒ€êµ¬ë³‘ì›","ëŒ€ì „ë³‘ì›","ì¸ì²œë³‘ì›",
             "êµìœ¡ì—°êµ¬ì›","ë³´í›ˆì›","ìˆ˜ì›ìš”ì–‘ì›","ê´‘ì£¼ìš”ì–‘ì›","ê¹€í•´ìš”ì–‘ì›","ëŒ€êµ¬ìš”ì–‘ì›",
             "ëŒ€ì „ìš”ì–‘ì›","ë‚¨ì–‘ì£¼ìš”ì–‘ì›","ì›ì£¼ìš”ì–‘ì›","ì „ì£¼ìš”ì–‘ì›","ì¬í™œì²´ìœ¡ì„¼í„°","íœ´ì–‘ì›"]

    df_group["ê¸°ê´€ëª…"] = pd.Categorical(df_group["ê¸°ê´€ëª…"], categories=ORDER, ordered=True)
    df_group = df_group.sort_values("ê¸°ê´€ëª…")

    st.dataframe(df_group, use_container_width=True)

    # ============================
    # ì‹ ê·œ ê¸°ëŠ¥ 4 â€” ì—ë„ˆì§€ ê¸°ë°˜ í”¼ë“œë°±
    # ============================

    st.markdown("## ì—ë„ˆì§€ ê¸°ë°˜ í”¼ë“œë°±")

    # í˜„ì¬ ì›” (í‘œì¤€ ìŠ¤í‚¤ë§ˆ df_all ì´ìš©)
    df_sel = df_all[df_all["ì—°ë„"]==selected_year]
    current_month = int(df_sel["ì›”"].max()) if not df_sel.empty else None

    # ëª©í‘œë‹¬ì„± ê°ì¶•ë¥  (Ví•©ê³„ / ê¸°ì¤€ë°°ì¶œëŸ‰)
    baseline = baseline_map.get(selected_year)
    reduction_ratio = total_V / baseline * 100 if baseline else None

    fb1, fb2 = st.columns(2)
    fb1.metric("í˜„ì¬ ì›”", f"{current_month}ì›”" if current_month else "-")
    fb2.metric("ëª©í‘œë‹¬ì„± ê°ì¶•ë¥ (V/ê¸°ì¤€)", "-" if reduction_ratio is None else f"{reduction_ratio:,.1f}%")

    # ê¸°ê´€ë³„ í”¼ë“œë°± í™•ì¥ (í‘œ)
    st.markdown("### ê¸°ê´€ë³„ ì—ë„ˆì§€ í”¼ë“œë°±(ìˆœìœ„Â·ê¶Œì¥ê°ì¶• ë“±)")

    df_fb = df_group.copy()

    # ì‚¬ìš© ë¶„í¬ ìˆœìœ„
    df_fb["ì‚¬ìš©ë¶„í¬ìˆœìœ„"] = df_fb["Uí•©ê³„"].rank(method="dense", ascending=False)

    # 3ê°œë…„ í‰ê·  ì¦ê°€ìœ¨ ìˆœìœ„
    df_fb["3ê°œë…„ì¦ê°€ìˆœìœ„"] = df_fb["3ê°œë…„ì¦ê°ë¥ "].rank(method="dense", ascending=False)

    # í‰ê· ëŒ€ë¹„ ì‚¬ìš©ë¹„ìœ¨ ìˆœìœ„
    df_fb["í‰ê· ëŒ€ë¹„ìˆœìœ„"] = df_fb["í‰ê· ëŒ€ë¹„ì‚¬ìš©ë¹„ìœ¨"].rank(method="dense", ascending=False)

    # ê¶Œì¥ ê°ì¶•ëŸ‰ = ì „ì²´ í•„ìš”ê°ì¶•ëŸ‰*(ê¸°ê´€Uë¹„ì¤‘)
    if baseline:
        need = total_V - baseline
        need = need if need>0 else 0
        df_fb["ê¶Œì¥ê°ì¶•ëŸ‰"] = need * (df_fb["Uí•©ê³„"]/total_U)
    else:
        df_fb["ê¶Œì¥ê°ì¶•ëŸ‰"] = None

    # ì¦ê°€ì‚¬ìœ  ì œì¶œ ì¡°ê±´ (ì¦ê°ë¥ >0 ë˜ëŠ” í‰ê· ë³´ë‹¤ ë†’ì€ ë¹„ìœ¨)
    def need_reason(row):
        if (row["3ê°œë…„ì¦ê°ë¥ "] is not None and row["3ê°œë…„ì¦ê°ë¥ "]>0) or \
           (row["í‰ê· ëŒ€ë¹„ì‚¬ìš©ë¹„ìœ¨"] is not None and row["í‰ê· ëŒ€ë¹„ì‚¬ìš©ë¹„ìœ¨"]>1):
            return "O"
        return "X"

    df_fb["ì¦ê°€ì‚¬ìœ ì œì¶œ"] = df_fb.apply(need_reason,axis=1)

    st.dataframe(df_fb, use_container_width=True)

    # ============================
    # ê¸°ì¡´ ìœ ì§€ êµ¬ê°„ â€“ ê³µë‹¨ ì „ì²´ ë¶„ì„ ì½”ë©˜íŠ¸
    # ============================

    st.markdown("## ê³µë‹¨ ì „ì²´ ë¶„ì„Â·ì½”ë©˜íŠ¸ (ê¸°ì¡´ ìœ ì§€)")

    actual_emission = analyzer.get_annual_ghg(df_all,by_agency=False).query("ì—°ë„==@selected_year")["ì—°ê°„ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰"].sum()
    recent_df,_ = analyzer.get_recent_years_ghg(analyzer.get_annual_ghg(df_all,by_agency=False), base_year=selected_year)

    fb_text = feedback.generate_overall_feedback(
        year=selected_year,
        actual_emission=actual_emission,
        baseline_emission=baseline,
        reduction_rate_pct=None,
        ratio_to_baseline=None,
        recent_total_df=recent_df,
        current_month=current_month,
    )
    st.write(fb_text)

# ============================================================
# 2) ê¸°ì¤€ë°°ì¶œëŸ‰ ê´€ë¦¬ íƒ­ (ê¸°ì¡´ ìœ ì§€)
# ============================================================

with tab_baseline:
    st.header("ê¸°ì¤€ë°°ì¶œëŸ‰ ê´€ë¦¬")
    # (ê¸°ì¡´ ì½”ë“œ ê·¸ëŒ€ë¡œ ìœ ì§€)
