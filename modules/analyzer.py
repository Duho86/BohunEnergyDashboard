from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, List, Mapping, Optional, Tuple

import numpy as np
import pandas as pd

try:
    import streamlit as st
except ImportError:  # í…ŒìŠ¤íŠ¸ í™˜ê²½ìš©
    st = None  # type: ignore[assignment]

from .loader import load_spec, get_org_order


# ======================================================================
# ê³µí†µ ìœ í‹¸
# ======================================================================


def _log_error(msg: str) -> None:
    if st is not None:
        st.error(msg)
    else:
        print(f"[ERROR] {msg}")


def _log_warning(msg: str) -> None:
    if st is not None:
        st.warning(msg)
    else:
        print(f"[WARN] {msg}")


# ======================================================================
# df_raw ê²°í•©
# ======================================================================


def _concat_raw(year_to_raw: Mapping[int, pd.DataFrame]) -> pd.DataFrame:
    """loader.load_energy_files ê°€ ë°˜í™˜í•œ year_to_raw ë¥¼ í•˜ë‚˜ì˜ dfë¡œ í•©ì¹œë‹¤.

    í•„ìˆ˜ ì»¬ëŸ¼ (loader.build_df_raw ê¸°ì¤€):
      ['ê¸°ê´€ëª…', 'ì‹œì„¤êµ¬ë¶„', 'ì—°ë©´ì ', 'ì—°ë‹¨ìœ„', 'ì—°ë„']
    """
    if not year_to_raw:
        raise ValueError(
            "year_to_raw ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ë¨¼ì € ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”."
        )

    required_cols = ["ê¸°ê´€ëª…", "ì‹œì„¤êµ¬ë¶„", "ì—°ë©´ì ", "ì—°ë‹¨ìœ„", "ì—°ë„"]
    dfs: List[pd.DataFrame] = []

    for year, df in year_to_raw.items():
        if df is None or df.empty:
            continue

        tmp = df.copy()

        # 1) í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        for col in required_cols:
            if col not in tmp.columns:
                raise ValueError(
                    f"{year}ë…„ df_rawì— '{col}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. "
                    "loader ë‹¨ê³„ì—ì„œ ìŠ¤í‚¤ë§ˆë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”."
                )

        # 2) ìˆ«ì ì»¬ëŸ¼ ì •ì œ
        num_cols = ["ì—°ë„", "ì—°ë©´ì ", "ì—°ë‹¨ìœ„"]
        for col in num_cols:
            tmp[col] = pd.to_numeric(tmp[col], errors="coerce")

        # 3) ìˆ«ì ì»¬ëŸ¼ì— NaN ì´ ìˆëŠ” í–‰ì€ ê²½ê³  í›„ ë¶„ì„ì—ì„œ ì œì™¸
        na_mask = tmp[num_cols].isna().any(axis=1)
        na_cnt = int(na_mask.sum())
        if na_cnt > 0:
            bad_rows = tmp.loc[na_mask, ["ê¸°ê´€ëª…", "ì—°ë„", "ì—°ë©´ì ", "ì—°ë‹¨ìœ„"]]
            _log_warning(
                f"{year}ë…„ df_rawì—ì„œ ì—°ë„/ì—°ë©´ì /ì—°ë‹¨ìœ„ì— NaN ì´ ìˆëŠ” í–‰ {na_cnt}ê°œë¥¼ ë¶„ì„ì—ì„œ ì œì™¸í•©ë‹ˆë‹¤.\n"
                f"{bad_rows.to_string(index=False)}"
            )
            tmp = tmp.loc[~na_mask].copy()

        dfs.append(tmp)

    if not dfs:
        raise ValueError("ìœ íš¨í•œ df_raw ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    df_all = pd.concat(dfs, ignore_index=True)

    # ì»¬ëŸ¼ í˜•ì‹ ì •ë¦¬
    df_all["ì—°ë„"] = df_all["ì—°ë„"].astype(int)
    df_all["ê¸°ê´€ëª…"] = df_all["ê¸°ê´€ëª…"].astype(str)
    df_all["ì‹œì„¤êµ¬ë¶„"] = df_all["ì‹œì„¤êµ¬ë¶„"].astype(str)

    return df_all


# ======================================================================
# data_2. ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë¶„ì„
# ======================================================================


@dataclass
class Data2Result:
    overall: pd.DataFrame
    by_org: pd.DataFrame


def _compute_overall_usage(
    df_all: pd.DataFrame, spec: dict, current_year: int
) -> pd.Series:
    """overall_current_year_usage + overall_yoy_and_3yr_change ê³„ì‚°."""
    analysis_years: List[int] = spec["meta"]["analysis_years"]

    if current_year not in analysis_years:
        raise ValueError(
            f"current_year={current_year} ê°€ meta.analysis_years ì— ì—†ìŠµë‹ˆë‹¤."
        )

    prev_year = current_year - 1
    if prev_year not in analysis_years:
        raise ValueError(f"ì „ë…„({prev_year}) ë°ì´í„°ê°€ meta.analysis_years ì— ì—†ìŠµë‹ˆë‹¤.")

    # ì—°ë„ë³„ ì „ì²´ ì‚¬ìš©ëŸ‰ í•©ê³„
    total_by_year = (
        df_all.groupby("ì—°ë„", dropna=False)["ì—°ë‹¨ìœ„"].sum().reindex(analysis_years)
    )

    if total_by_year.isna().any():
        raise ValueError("ì—°ë„ë³„ ì—°ë‹¨ìœ„ í•©ê³„ ê³„ì‚° ì¤‘ NaN ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

    cur = float(total_by_year.loc[current_year])
    prev = float(total_by_year.loc[prev_year])

    # current_year ì´ì „ ì—°ë„ ì¤‘ì—ì„œ ë§ˆì§€ë§‰ 3ê°œë…„
    past_years = [y for y in analysis_years if y < current_year]
    three_years = past_years[-3:]
    avg3 = float(total_by_year.loc[three_years].mean())

    if prev == 0 or avg3 == 0:
        raise ValueError("ì „ë…„ ë˜ëŠ” 3ê°œë…„ í‰ê·  ì‚¬ìš©ëŸ‰ì´ 0ì…ë‹ˆë‹¤. ê³„ì‚°ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")

    yoy_rate = (cur - prev) / prev
    vs3_rate = (cur - avg3) / avg3

    return pd.Series(
        {
            "ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(í˜„ì¬ ê¸°ì¤€)": cur,
            "ì „ë…„ëŒ€ë¹„ ì¦ê°ë¥ ": yoy_rate,
            "3ê°œë…„ í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ëŒ€ë¹„ ì¦ê°ë¥ ": vs3_rate,
        }
    )


def _compute_overall_by_facility(df_all: pd.DataFrame, current_year: int) -> pd.Series:
    """
    ì‹œì„¤êµ¬ë¶„ë³„ 'ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨' í‰ê· ì„ ê³„ì‚°í•œë‹¤.

    ì—¬ê¸°ì„œëŠ” ê° ê¸°ê´€ë³„ë¡œ (ì—°ë©´ì  / ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰)ì„ êµ¬í•œ ë’¤
    ì˜ë£Œ/ë³µì§€/ê¸°íƒ€ ì‹œì„¤êµ¬ë¶„ë³„ë¡œ ë‹¨ìˆœ í‰ê· ì„ ë‚¸ë‹¤.
    """
    df_year = df_all[df_all["ì—°ë„"] == current_year].copy()
    if df_year.empty:
        raise ValueError(f"{current_year}ë…„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ê¸°ê´€ë³„ í˜„ì¬ ì—°ë„ ì‚¬ìš©ëŸ‰ ë° ì—°ë©´ì 
    usage_by_org = df_year.groupby("ê¸°ê´€ëª…", dropna=False)["ì—°ë‹¨ìœ„"].sum()
    area_by_org = df_year.groupby("ê¸°ê´€ëª…", dropna=False)["ì—°ë©´ì "].max()
    fac_type_by_org = df_year.groupby("ê¸°ê´€ëª…", dropna=False)["ì‹œì„¤êµ¬ë¶„"].agg(
        lambda x: x.mode().iloc[0] if not x.mode().empty else x.iloc[0]
    )

    # ì‚¬ìš©ëŸ‰ì´ 0 ì´í•˜ì¸ ê¸°ê´€ì€ ê³„ì‚°ì—ì„œ ì œì™¸
    valid_mask = usage_by_org > 0
    if not valid_mask.all():
        _log_warning("ì¼ë¶€ ê¸°ê´€ì—ì„œ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ì´ 0 ì´í•˜ì…ë‹ˆë‹¤. ë©´ì ëŒ€ë¹„ ì‚¬ìš©ë¹„ìœ¨ ê³„ì‚°ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.")
        usage_by_org = usage_by_org[valid_mask]
        area_by_org = area_by_org[valid_mask]
        fac_type_by_org = fac_type_by_org[valid_mask]

    # ğŸ”´ ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨: ì—°ë©´ì  / ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰
    upa_org = area_by_org / usage_by_org

    df_org = pd.DataFrame(
        {
            "ì‹œì„¤êµ¬ë¶„": fac_type_by_org,
            "ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨": upa_org,
        }
    )

    grp = df_org.groupby("ì‹œì„¤êµ¬ë¶„", dropna=False)["ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨"].mean()

    def get_value(ftype: str) -> float:
        return float(grp.get(ftype, np.nan))

    return pd.Series(
        {
            "ì˜ë£Œì‹œì„¤": get_value("ì˜ë£Œì‹œì„¤"),
            "ë³µì§€ì‹œì„¤": get_value("ë³µì§€ì‹œì„¤"),
            "ê¸°íƒ€ì‹œì„¤": get_value("ê¸°íƒ€ì‹œì„¤"),
        }
    )


def _compute_org_level_current_metrics(
    df_all: pd.DataFrame,
    spec: dict,
    current_year: int,
) -> pd.DataFrame:
    ...
    # ì—°ë„ í•„í„°/í”¼ë²—ì€ ê¸°ì¡´ê³¼ ë™ì¼ (years_filter, usage_by_year_org ë“± ìƒì„±)

    years = sorted(years_filter)
    usage_by_year_org = usage_by_year_org[years]

    area_by_org = df.groupby("ê¸°ê´€ëª…", dropna=False)["ì—°ë©´ì "].max()
    fac_type_by_org = df.groupby("ê¸°ê´€ëª…", dropna=False)["ì‹œì„¤êµ¬ë¶„"].agg(
        lambda x: x.mode().iloc[0] if not x.mode().empty else x.iloc[0]
    )

    if current_year not in usage_by_year_org.columns:
        usage_by_year_org[current_year] = 0.0
    usage_cur = usage_by_year_org[current_year]

    # ğŸ”¹ 3ê°œë…„ í‰ê· (ì—°ë„ë³„ ê° ì†Œì†ê¸°êµ¬ë³„ í‰ê· ) â€“ '1. ë°±ë°ì´í„° ë¶„ì„'ê³¼ ë™ì¼ ë°©ì‹
    baseline_by_year_org = pd.DataFrame(
        index=usage_by_year_org.index, columns=years, dtype=float
    )
    for i, y in enumerate(years):
        prev_years = years[:i][-3:]  # ë°”ë¡œ ì•ì˜ ìµœëŒ€ 3ê°œë…„
        if prev_years:
            baseline_by_year_org[y] = usage_by_year_org[prev_years].mean(axis=1)
        else:
            # ì´ˆê¸° 3ë…„ ì´ì „ì—ëŠ” í•´ë‹¹ ì—°ë„ ìì²´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ (ì¦ê°ë¥  0)
            baseline_by_year_org[y] = usage_by_year_org[y]

    if current_year not in baseline_by_year_org.columns:
        raise ValueError(f"{current_year}ë…„ì˜ 3ê°œë…„ í‰ê·  ê¸°ì¤€ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    baseline_cur = baseline_by_year_org[current_year]

    # ğŸ”¹ 3ê°œë…„ í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ëŒ€ë¹„ ì¦ê°ë¥ 
    vs3 = (usage_cur - baseline_cur) / baseline_cur.replace(0, np.nan)

    # ğŸ”´ ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨: ì—°ë©´ì  / ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰
    upa = area_by_org / usage_cur.replace(0, np.nan)

    total_cur = float(usage_cur.sum())
    if total_cur == 0:
        raise ValueError("í˜„ì¬ì—°ë„ ì „ì²´ ì‚¬ìš©ëŸ‰ í•©ê³„ê°€ 0ì…ë‹ˆë‹¤.")

    share = usage_cur / total_cur

    df_org = pd.DataFrame(
        {
            "ì‹œì„¤êµ¬ë¶„": fac_type_by_org,
            "ì—°ë©´ì ": area_by_org,
            "ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰": usage_cur,
            "ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨": upa,
            "ì—ë„ˆì§€ ì‚¬ìš© ë¹„ì¤‘": share,
            "3ê°œë…„ í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ëŒ€ë¹„ ì¦ê°ë¥ ": vs3,
        }
    )

    facility_mean = df_org.groupby("ì‹œì„¤êµ¬ë¶„", dropna=False)[
        "ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨"
    ].transform("mean")
    df_org["ì‹œì„¤ë³„ í‰ê·  ë©´ì  ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨"] = (
        df_org["ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨"]
        / facility_mean.replace(0, np.nan)
    )

    return df_org



def build_data_2_usage_analysis(
    year_to_raw: Mapping[int, pd.DataFrame],
    current_year: Optional[int] = None,
) -> Data2Result:
    """data_2. ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë¶„ì„ ì „ì²´ ê³„ì‚°."""
    spec = load_spec()
    df_all = _concat_raw(year_to_raw)

    if current_year is None:
        current_year = int(spec["meta"]["current_year"])

    # 1) ê³µë‹¨ ì „ì²´
    s_overall_usage = _compute_overall_usage(df_all, spec, current_year)
    s_fac = _compute_overall_by_facility(df_all, current_year)
    s_all = pd.concat([s_overall_usage, s_fac])
    df_overall = s_all.to_frame().T
    df_overall.index = ["ì „ ì²´"]

    # 2) ì†Œì†ê¸°êµ¬ë³„
    df_by_org = _compute_org_level_current_metrics(df_all, spec, current_year)

    return Data2Result(overall=df_overall, by_org=df_by_org)


# ======================================================================
# data_3. í”¼ë“œë°±
# ======================================================================


@dataclass
class Data3Result:
    overall: pd.DataFrame
    by_org: pd.DataFrame
    detail: pd.DataFrame


def _compute_overall_feedback(
    df_all: pd.DataFrame,
    spec: dict,
    current_year: int,
) -> pd.Series:
    """overall_recommended_usage_by_ndc ê³„ì‚°."""
    analysis_years: List[int] = spec["meta"]["analysis_years"]
    ndc_rate: float = float(spec["meta"]["ndc_target_rate"])

    total_by_year = (
        df_all.groupby("ì—°ë„", dropna=False)["ì—°ë‹¨ìœ„"].sum().reindex(analysis_years)
    )
    if total_by_year.isna().any():
        raise ValueError("ì—°ë„ë³„ ì—°ë‹¨ìœ„ í•©ê³„ ê³„ì‚° ì¤‘ NaN ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

    cur = float(total_by_year.loc[current_year])

    # current_year ì´ì „ ì—°ë„ ì¤‘ ë§ˆì§€ë§‰ 3ê°œë…„
    past_years = [y for y in analysis_years if y < current_year]
    three_years = past_years[-3:]
    avg3 = float(total_by_year.loc[three_years].mean())

    if avg3 == 0:
        raise ValueError("3ê°œë…„ í‰ê·  ì‚¬ìš©ëŸ‰ì´ 0ì…ë‹ˆë‹¤.")

    # ì—‘ì…€: ê¶Œì¥ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ = í˜„ì¬ ì‚¬ìš©ëŸ‰ * (1 - ndc_rate)
    recommended = cur * (1.0 - ndc_rate)
    reduction_yoy = -ndc_rate  # ì „ë…„ëŒ€ë¹„ ê°ì¶•ë¥ (ëª©í‘œê°’)
    # 3ê°œë…„ ëŒ€ë¹„ ê°ì¶•ë¥  = (ê¶Œì¥ëŸ‰ - 3ê°œë…„ í‰ê· ) / 3ê°œë…„ í‰ê· 
    reduction_vs3 = (recommended - avg3) / avg3

    return pd.Series(
        {
            "ê¶Œì¥ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰": recommended,
            "ì „ë…„ëŒ€ë¹„ ê°ì¶•ë¥ ": reduction_yoy,
            "3ê°œë…„ ëŒ€ë¹„ ê°ì¶•ë¥ ": reduction_vs3,
        }
    )


def _compute_org_recommended_and_flags(
    df_org_metrics: pd.DataFrame,
    spec: dict,
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    org_level_recommended_usage_and_flags + ìƒì„¸ ê´€ë¦¬ëŒ€ìƒ í‘œ ìƒì„±.

    ì—‘ì…€ ê¸°ì¤€:
      - ì‚¬ìš© ë¶„í¬ ìˆœìœ„: ì—ë„ˆì§€ ì‚¬ìš© ë¹„ì¤‘(Fì—´)ì„ ê¸°ì¤€ìœ¼ë¡œ RANK.AVG
      - ì—ë„ˆì§€ 3ê°œë…„ í‰ê·  ì¦ê°€ ìˆœìœ„: 3ê°œë…„ í‰ê·  ëŒ€ë¹„ ì¦ê°ë¥ (Gì—´) ê¸°ì¤€ RANK.AVG
      - í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(ì—°ë©´ì  ê¸°ì¤€) ìˆœìœ„: ë©´ì ëŒ€ë¹„ ì‚¬ìš©ë¹„ìœ¨(Eì—´) ê¸°ì¤€ RANK.AVG
      - ê¶Œì¥ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰: í˜„ì¬ ì‚¬ìš©ëŸ‰ * (1 - ndc_rate)
      - ê¶Œì¥ ì‚¬ìš©ëŸ‰ ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš© ë¹„ìœ¨: í˜„ì¬ ì‚¬ìš©ëŸ‰ / ê¶Œì¥ ì‚¬ìš©ëŸ‰
      - ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ê´€ë¦¬ ëŒ€ìƒ(O/X):
          OR(ë©´ì ëŒ€ë¹„ ì‚¬ìš©ë¹„ìœ¨ > ì „ì²´ í‰ê· ,
             3ê°œë…„ í‰ê·  ëŒ€ë¹„ ì¦ê°ë¥  > ì „ì²´ í‰ê· ,
             ê¶Œì¥ë¹„ìœ¨ > ì „ì²´ í‰ê· )
      - ìƒì„¸ í‘œ:
          ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ê³¼ì‚¬ìš©                : ìœ„ì˜ ì²« ë²ˆì§¸ ì¡°ê±´
          ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ê¸‰ì¦(3ê°œë…„ í‰ê· ëŒ€ë¹„)     : ë‘ ë²ˆì§¸ ì¡°ê±´
          ê¶Œì¥ëŸ‰ ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë§¤ìš° ì´ˆê³¼     : ì„¸ ë²ˆì§¸ ì¡°ê±´
    """
    ndc_rate: float = float(spec["meta"]["ndc_target_rate"])

    # df_org_metrics ëŠ” _compute_org_level_current_metrics ê²°ê³¼
    cur_usage = df_org_metrics["ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰"]
    share = df_org_metrics["ì—ë„ˆì§€ ì‚¬ìš© ë¹„ì¤‘"]
    upa = df_org_metrics["ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨"]
    growth_rate = df_org_metrics["3ê°œë…„ í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ëŒ€ë¹„ ì¦ê°ë¥ "]

    # ê¶Œì¥ ì‚¬ìš©ëŸ‰ ë° ë¹„ìœ¨
    recommended = cur_usage * (1.0 - ndc_rate)
    usage_vs_recommended = cur_usage / recommended.replace(0, np.nan)

    # ìˆœìœ„ ê³„ì‚° (ì—‘ì…€ RANK.AVGì™€ ë™ì¼í•˜ê²Œ ë‚´ë¦¼ì°¨ìˆœ, ë™ìˆœìœ„ ë™ì¼ ìˆœìœ„)
    rank_by_usage = share.rank(ascending=False, method="average")
    rank_by_growth = growth_rate.rank(ascending=False, method="average")
    rank_by_upa = upa.rank(ascending=False, method="average")

    # NaN ìˆœìœ„ëŠ” 0ìœ¼ë¡œ í‘œê¸°
    if (
        rank_by_usage.isna().any()
        or rank_by_growth.isna().any()
        or rank_by_upa.isna().any()
    ):
        _log_warning("ì¼ë¶€ ê¸°ê´€ì—ì„œ ìˆœìœ„ ê³„ì‚°ì— NaN ì´ ë°œìƒí•˜ì—¬ ìˆœìœ„ë¥¼ 0ìœ¼ë¡œ í‘œê¸°í•©ë‹ˆë‹¤.")

    rank_by_usage_val = rank_by_usage.fillna(0.0)
    rank_by_growth_val = rank_by_growth.fillna(0.0)
    rank_by_upa_val = rank_by_upa.fillna(0.0)

    # ê´€ë¦¬ ëŒ€ìƒ í”Œë˜ê·¸ìš© ê¸°ì¤€ê°’ (ì „ì²´ í‰ê· )
    upa_mean_overall = float(upa.mean())
    growth_mean_overall = float(growth_rate.mean())
    uv_mean_overall = float(usage_vs_recommended.mean())

    cond_area = upa > upa_mean_overall
    cond_growth = growth_rate > growth_mean_overall
    cond_uv = usage_vs_recommended > uv_mean_overall

    management_flag = (cond_area | cond_growth | cond_uv).fillna(False)
    flag_text = management_flag.map(lambda x: "O" if x else "X")

    df_by_org = pd.DataFrame(
        {
            "ì‚¬ìš© ë¶„í¬ ìˆœìœ„": rank_by_usage_val,
            "ì—ë„ˆì§€ 3ê°œë…„ í‰ê·  ì¦ê°€ ìˆœìœ„": rank_by_growth_val,
            "í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(ì—°ë©´ì  ê¸°ì¤€) ìˆœìœ„": rank_by_upa_val,
            "ê¶Œì¥ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰": recommended,
            "ê¶Œì¥ ì‚¬ìš©ëŸ‰ ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš© ë¹„ìœ¨": usage_vs_recommended,
            "ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ê´€ë¦¬ ëŒ€ìƒ": flag_text,
        },
        index=df_org_metrics.index,
    )

    # ìƒì„¸ ê´€ë¦¬ëŒ€ìƒ í‘œ (ê° ì¡°ê±´ë³„ O/X)
    df_detail = pd.DataFrame(index=df_org_metrics.index)
    df_detail["ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ê³¼ì‚¬ìš©"] = cond_area.fillna(False).map(
        lambda x: "O" if x else "X"
    )
    df_detail["ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ê¸‰ì¦(3ê°œë…„ í‰ê· ëŒ€ë¹„)"] = cond_growth.fillna(False).map(
        lambda x: "O" if x else "X"
    )
    df_detail["ê¶Œì¥ëŸ‰ ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë§¤ìš° ì´ˆê³¼"] = cond_uv.fillna(False).map(
        lambda x: "O" if x else "X"
    )

    return df_by_org, df_detail


def build_data_3_feedback(
    year_to_raw: Mapping[int, pd.DataFrame],
    current_year: Optional[int] = None,
) -> Data3Result:
    """data_3. í”¼ë“œë°± ì „ì²´ ê³„ì‚°."""
    spec = load_spec()
    df_all = _concat_raw(year_to_raw)

    if current_year is None:
        current_year = int(spec["meta"]["current_year"])

    # 1) ê³µë‹¨ ì „ì²´
    s_overall = _compute_overall_feedback(df_all, spec, current_year)
    df_overall = s_overall.to_frame().T
    df_overall.index = ["ê³µë‹¨ ì „ì²´"]

    # 2) ì†Œì†ê¸°êµ¬ë³„ metrics (data_2ì™€ ë™ì¼ ë¡œì§ ì¬ì‚¬ìš©)
    df_org_metrics = _compute_org_level_current_metrics(df_all, spec, current_year)

    # 3) ê¶Œì¥ ì‚¬ìš©ëŸ‰ / ê´€ë¦¬ëŒ€ìƒ í”Œë˜ê·¸ / ìƒì„¸ í‘œ
    df_by_org, df_detail = _compute_org_recommended_and_flags(df_org_metrics, spec)

    return Data3Result(overall=df_overall, by_org=df_by_org, detail=df_detail)


# ======================================================================
# ê¸°ì¡´ app í˜¸í™˜ìš© ë˜í¼
# ======================================================================


def compute_facility_feedback(
    selected_year: int,
    year_to_raw: Mapping[int, pd.DataFrame],
):
    """ê¸°ì¡´ app.py ì—ì„œ ì‚¬ìš© ì¤‘ì¸ ì¸í„°í˜ì´ìŠ¤ë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•œ ë˜í¼."""
    result = build_data_3_feedback(year_to_raw, current_year=selected_year)
    return result.by_org, result.detail
