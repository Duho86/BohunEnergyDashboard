from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, List, Mapping, Optional, Tuple

import numpy as np
import pandas as pd

try:
    import streamlit as st
except ImportError:
    st = None  # type: ignore[assignment]

from .loader import load_spec, get_org_order


# ===============================
# ë¡œê·¸ ìœ í‹¸
# ===============================
def _log_error(msg: str) -> None:
    if st is not None:
        st.error(msg)
    else:
        print("[ERROR]", msg)


def _log_warning(msg: str) -> None:
    if st is not None:
        st.warning(msg)
    else:
        print("[WARN]", msg)


# ===============================
# df_raw ê²°í•©
# ===============================
def _concat_raw(year_to_raw: Mapping[int, pd.DataFrame]) -> pd.DataFrame:
    if not year_to_raw:
        raise ValueError("year_to_raw ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")

    required_cols = ["ê¸°ê´€ëª…", "ì‹œì„¤êµ¬ë¶„", "ì—°ë©´ì ", "ì—°ë‹¨ìœ„", "ì—°ë„"]
    dfs: List[pd.DataFrame] = []

    for year, df in year_to_raw.items():
        if df is None or df.empty:
            continue

        tmp = df.copy()

        # ì—‘ì…€ í•©ê³„í–‰(ê¸°ê´€ëª…='í•©ê³„' & ì—°ë©´ì /ì—°ë‹¨ìœ„ NaN)ì€ ë¯¸ë¦¬ ì œê±°
        if {"ê¸°ê´€ëª…", "ì—°ë©´ì ", "ì—°ë‹¨ìœ„"}.issubset(tmp.columns):
            mask_total = (
                tmp["ê¸°ê´€ëª…"].astype(str).str.strip().eq("í•©ê³„")
                & tmp["ì—°ë©´ì "].isna()
                & tmp["ì—°ë‹¨ìœ„"].isna()
            )
            if mask_total.any():
                tmp = tmp.loc[~mask_total].copy()

        # í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬
        for col in required_cols:
            if col not in tmp.columns:
                raise ValueError(
                    f"{year}ë…„ df_rawì— '{col}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. loader ìŠ¤í‚¤ë§ˆë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”."
                )

        # ìˆ«ì ì»¬ëŸ¼ ì •ì œ
        num_cols = ["ì—°ë„", "ì—°ë©´ì ", "ì—°ë‹¨ìœ„"]
        for col in num_cols:
            tmp[col] = pd.to_numeric(tmp[col], errors="coerce")

        # NaN ìˆëŠ” í–‰ ì œì™¸ + ê²½ê³ 
        na_mask = tmp[num_cols].isna().any(axis=1)
        na_cnt = int(na_mask.sum())
        if na_cnt > 0:
            bad_rows = tmp.loc[na_mask, ["ê¸°ê´€ëª…", "ì—°ë„", "ì—°ë©´ì ", "ì—°ë‹¨ìœ„"]]
            _log_warning(
                f"{year}ë…„ df_rawì—ì„œ ì—°ë„/ì—°ë©´ì /ì—°ë‹¨ìœ„ì— NaN ì´ ìˆëŠ” í–‰ {na_cnt}ê°œë¥¼ ë¶„ì„ì—ì„œ ì œì™¸í•©ë‹ˆë‹¤.\n"
                f"{bad_rows.to_string(index=False)}"
            )
            tmp = tmp.loc[~na_mask].copy()

        dfs.append(tmp)

    if not dfs:
        raise ValueError("ìœ íš¨í•œ df_raw ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    df_all = pd.concat(dfs, ignore_index=True)
    df_all["ì—°ë„"] = df_all["ì—°ë„"].astype(int)
    df_all["ê¸°ê´€ëª…"] = df_all["ê¸°ê´€ëª…"].astype(str)
    df_all["ì‹œì„¤êµ¬ë¶„"] = df_all["ì‹œì„¤êµ¬ë¶„"].astype(str)
    return df_all


# ===============================
# data_2 â€“ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë¶„ì„
# ===============================
@dataclass
class Data2Result:
    overall: pd.DataFrame
    by_org: pd.DataFrame
    baseline_by_org: pd.Series  # ê° ê¸°ê´€ë³„ 3ê°œë…„ í‰ê·  (ì—‘ì…€ B7, U7ì— í•´ë‹¹)


def _compute_overall_usage(
    df_all: pd.DataFrame, spec: dict, current_year: int
) -> pd.Series:
    analysis_years: List[int] = spec["meta"]["analysis_years"]

    if current_year not in analysis_years:
        raise ValueError(
            f"current_year={current_year} ê°€ meta.analysis_years ì— ì—†ìŠµë‹ˆë‹¤."
        )

    prev_year = current_year - 1
    if prev_year not in analysis_years:
        raise ValueError(f"ì „ë…„({prev_year}) ë°ì´í„°ê°€ meta.analysis_years ì— ì—†ìŠµë‹ˆë‹¤.")

    total_by_year = (
        df_all.groupby("ì—°ë„", dropna=False)["ì—°ë‹¨ìœ„"].sum().reindex(analysis_years)
    )
    if total_by_year.isna().any():
        raise ValueError("ì—°ë„ë³„ ì—°ë‹¨ìœ„ í•©ê³„ ê³„ì‚° ì¤‘ NaN ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

    cur = float(total_by_year.loc[current_year])
    prev = float(total_by_year.loc[prev_year])

    past_years = [y for y in analysis_years if y < current_year]
    three_years = past_years[-3:]
    avg3 = float(total_by_year.loc[three_years].mean())

    if prev == 0 or avg3 == 0:
        raise ValueError("ì „ë…„ ë˜ëŠ” 3ê°œë…„ í‰ê·  ì‚¬ìš©ëŸ‰ì´ 0ì…ë‹ˆë‹¤.")

    yoy_rate = (cur - prev) / prev
    vs3_rate = (cur - avg3) / avg3

    return pd.Series(
        {
            "ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(í˜„ì¬ ê¸°ì¤€)": cur,
            "ì „ë…„ëŒ€ë¹„ ì¦ê°ë¥ ": yoy_rate,
            "3ê°œë…„ í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ëŒ€ë¹„ ì¦ê°ë¥ ": vs3_rate,
        }
    )


def _compute_overall_by_facility(
    df_all: pd.DataFrame, current_year: int
) -> pd.Series:
    """
    ì‹œì„¤êµ¬ë¶„ë³„ 'ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨' í‰ê· .

    âœ” ì—‘ì…€ ì •ì˜:
      - ê¸°ê´€ë³„ ë©´ì ëŒ€ë¹„ ë¹„ìœ¨ = ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ / ì—°ë©´ì 
      - ì‹œì„¤êµ¬ë¶„ë³„ í‰ê·  = ê·¸ ê¸°ê´€ë“¤ì˜ ë‹¨ìˆœ í‰ê· 
    """
    df_year = df_all[df_all["ì—°ë„"] == current_year].copy()
    if df_year.empty:
        raise ValueError(f"{current_year}ë…„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    usage_by_org = df_year.groupby("ê¸°ê´€ëª…", dropna=False)["ì—°ë‹¨ìœ„"].sum()
    area_by_org = df_year.groupby("ê¸°ê´€ëª…", dropna=False)["ì—°ë©´ì "].max()
    fac_type_by_org = df_year.groupby("ê¸°ê´€ëª…", dropna=False)["ì‹œì„¤êµ¬ë¶„"].agg(
        lambda x: x.mode().iloc[0] if not x.mode().empty else x.iloc[0]
    )

    # ì‚¬ìš©ëŸ‰=0 ë˜ëŠ” ë©´ì <=0 ê¸°ê´€ ì œì™¸
    valid_mask = (usage_by_org > 0) & (area_by_org > 0)
    if not valid_mask.all():
        _log_warning(
            "ì¼ë¶€ ê¸°ê´€ì—ì„œ ì—°ë©´ì  ë˜ëŠ” ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ì´ 0 ì´í•˜ì…ë‹ˆë‹¤. "
            "ë©´ì ëŒ€ë¹„ ì‚¬ìš©ë¹„ìœ¨ ê³„ì‚°ì—ì„œ ì œì™¸í•©ë‹ˆë‹¤."
        )
        usage_by_org = usage_by_org[valid_mask]
        area_by_org = area_by_org[valid_mask]
        fac_type_by_org = fac_type_by_org[valid_mask]

    # âœ… ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ / ì—°ë©´ì 
    upa_org = usage_by_org / area_by_org

    df_org = pd.DataFrame(
        {
            "ì‹œì„¤êµ¬ë¶„": fac_type_by_org,
            "ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨": upa_org,
        }
    )

    grp = df_org.groupby("ì‹œì„¤êµ¬ë¶„", dropna=False)["ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨"].mean()

    def get_value(ftype: str) -> float:
        return float(grp.get(ftype, np.nan))

    return pd.Series(
        {
            "ì˜ë£Œì‹œì„¤": get_value("ì˜ë£Œì‹œì„¤"),
            "ë³µì§€ì‹œì„¤": get_value("ë³µì§€ì‹œì„¤"),
            "ê¸°íƒ€ì‹œì„¤": get_value("ê¸°íƒ€ì‹œì„¤"),
        }
    )


def _compute_org_level_current_metrics(
    df_all: pd.DataFrame,
    spec: dict,
    current_year: int,
) -> Tuple[pd.DataFrame, pd.Series]:
    """
    org_level_current_year_metrics êµ¬í˜„.

    ë°˜í™˜:
      - df_org: ê¸°ê´€ë³„ í˜„ì¬ì—°ë„ ì§€í‘œ
      - baseline_cur: ê¸°ê´€ë³„ 3ê°œë…„ í‰ê·  ì‚¬ìš©ëŸ‰ (ì—‘ì…€ '1. ë°±ë°ì´í„° ë¶„ì„'!B7 / U7 ì—­í• )
    """
    calc_conf = None
    for c in spec["logic"]["rules"]["calculations"]:
        if c.get("name") == "org_level_current_year_metrics":
            calc_conf = c
            break
    if calc_conf is None:
        raise ValueError("spec.logic.rules.calculations ì— org_level_current_year_metrics ì—†ìŒ")

    years_filter: List[int] = []
    for f in calc_conf.get("filters", []):
        if f.get("field") == "year" and f.get("op") == "in":
            years_filter = list(f.get("value", []))
            break
    if not years_filter:
        raise ValueError("org_level_current_year_metrics ì˜ year in í•„í„°ë¥¼ spec ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    df = df_all[df_all["ì—°ë„"].isin(years_filter)].copy()
    if df.empty:
        raise ValueError(f"year in {years_filter} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    years = sorted([y for y in years_filter if y in df["ì—°ë„"].unique()])

    usage_by_year_org = (
        df.groupby(["ê¸°ê´€ëª…", "ì—°ë„"], dropna=False)["ì—°ë‹¨ìœ„"].sum().unstack("ì—°ë„")
    )
    for y in years:
        if y not in usage_by_year_org.columns:
            usage_by_year_org[y] = 0.0
    usage_by_year_org = usage_by_year_org[years]

    area_by_org = df.groupby("ê¸°ê´€ëª…", dropna=False)["ì—°ë©´ì "].max()
    fac_type_by_org = df.groupby("ê¸°ê´€ëª…", dropna=False)["ì‹œì„¤êµ¬ë¶„"].agg(
        lambda x: x.mode().iloc[0] if not x.mode().empty else x.iloc[0]
    )

    if current_year not in usage_by_year_org.columns:
        usage_by_year_org[current_year] = 0.0
    usage_cur = usage_by_year_org[current_year]

    # ğŸ”¹ ê¸°ê´€ë³„ 3ê°œë…„ í‰ê·  (ì—‘ì…€ B7 / U7)
    baseline_by_year_org = pd.DataFrame(
        index=usage_by_year_org.index, columns=years, dtype=float
    )
    for i, y in enumerate(years):
        prev_years = years[:i][-3:]
        if prev_years:
            baseline_by_year_org[y] = usage_by_year_org[prev_years].mean(axis=1)
        else:
            baseline_by_year_org[y] = usage_by_year_org[y]
    if current_year not in baseline_by_year_org.columns:
        raise ValueError(f"{current_year}ë…„ì˜ 3ê°œë…„ í‰ê·  ê¸°ì¤€ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    baseline_cur = baseline_by_year_org[current_year]

    # 3ê°œë…„ í‰ê·  ëŒ€ë¹„ ì¦ê°ë¥ 
    vs3 = (usage_cur - baseline_cur) / baseline_cur.replace(0, np.nan)

    # âœ… ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨ = ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ / ì—°ë©´ì 
    upa = usage_cur / area_by_org.replace(0, np.nan)

    total_cur = float(usage_cur.sum())
    if total_cur == 0:
        raise ValueError("í˜„ì¬ì—°ë„ ì „ì²´ ì‚¬ìš©ëŸ‰ í•©ê³„ê°€ 0ì…ë‹ˆë‹¤.")

    share = usage_cur / total_cur

    df_org = pd.DataFrame(
        {
            "ì‹œì„¤êµ¬ë¶„": fac_type_by_org,
            "ì—°ë©´ì ": area_by_org,
            "ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰": usage_cur,
            "ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨": upa,
            "ì—ë„ˆì§€ ì‚¬ìš© ë¹„ì¤‘": share,
            "3ê°œë…„ í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ëŒ€ë¹„ ì¦ê°ë¥ ": vs3,
        }
    )

    # ì‹œì„¤ë³„ í‰ê·  ëŒ€ë¹„ ë¹„ìœ¨
    facility_mean = df_org.groupby("ì‹œì„¤êµ¬ë¶„", dropna=False)[
        "ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨"
    ].transform("mean")
    df_org["ì‹œì„¤ë³„ í‰ê·  ë©´ì  ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨"] = (
        df_org["ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨"] / facility_mean.replace(0, np.nan)
    )

    return df_org, baseline_cur


def build_data_2_usage_analysis(
    year_to_raw: Mapping[int, pd.DataFrame],
    current_year: Optional[int] = None,
) -> Data2Result:
    spec = load_spec()
    df_all = _concat_raw(year_to_raw)

    if current_year is None:
        current_year = int(spec["meta"]["current_year"])

    s_overall_usage = _compute_overall_usage(df_all, spec, current_year)
    s_fac = _compute_overall_by_facility(df_all, current_year)
    s_all = pd.concat([s_overall_usage, s_fac])
    df_overall = s_all.to_frame().T
    df_overall.index = ["ì „ ì²´"]

    df_by_org, baseline_cur = _compute_org_level_current_metrics(
        df_all, spec, current_year
    )

    return Data2Result(overall=df_overall, by_org=df_by_org, baseline_by_org=baseline_cur)


# ===============================
# data_3 â€“ í”¼ë“œë°±
# ===============================
@dataclass
class Data3Result:
    overall: pd.DataFrame
    by_org: pd.DataFrame
    detail: pd.DataFrame


def _compute_overall_feedback(
    df_all: pd.DataFrame,
    spec: dict,
    current_year: int,
    baseline_by_org: pd.Series,
) -> pd.Series:
    """
    ê³µë‹¨ ì „ì²´ í”¼ë“œë°±.

    ì—‘ì…€ ë¡œì§ì— ë§ì¶°:
      - ê¶Œì¥ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ = (ê³µë‹¨ ì „ì²´ 3ê°œë…„ í‰ê· ) Ã— (1 - NDC)
         â†’ baseline_by_org í•©ê³„ Ã— (1 - ndc_rate)
      - ì „ë…„ëŒ€ë¹„ ê°ì¶•ë¥  = -NDC (ëª©í‘œì¹˜)
      - 3ê°œë…„ ëŒ€ë¹„ ê°ì¶•ë¥  = (ê¶Œì¥ëŸ‰ - 3ê°œë…„ í‰ê·  ì „ì²´)/3ê°œë…„ í‰ê·  ì „ì²´
    """
    analysis_years: List[int] = spec["meta"]["analysis_years"]
    ndc_rate: float = float(spec["meta"]["ndc_target_rate"])

    total_by_year = (
        df_all.groupby("ì—°ë„", dropna=False)["ì—°ë‹¨ìœ„"].sum().reindex(analysis_years)
    )
    if total_by_year.isna().any():
        raise ValueError("ì—°ë„ë³„ ì—°ë‹¨ìœ„ í•©ê³„ ê³„ì‚° ì¤‘ NaN ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

    # ê³µë‹¨ ì „ì²´ 3ê°œë…„ í‰ê·  (ì—‘ì…€ U7)
    baseline_total = float(baseline_by_org.sum())

    # ìµœê·¼ 3ê°œë…„ ì „ì²´ í‰ê·  (ì—‘ì…€ U23 ìœ ì‚¬ â€“ ì™„ì „ ë™ì¼í•˜ì§€ ì•Šì„ ìˆ˜ ìˆì§€ë§Œ ìµœëŒ€í•œ ê·¼ì ‘)
    past_years = [y for y in analysis_years if y < current_year]
    three_years = past_years[-3:]
    baseline_total_ref = float(total_by_year.loc[three_years].mean())

    recommended = baseline_total * (1.0 - ndc_rate)
    if baseline_total_ref == 0:
        vs3_reduction = np.nan
    else:
        vs3_reduction = (recommended - baseline_total_ref) / baseline_total_ref

    reduction_yoy = -ndc_rate

    return pd.Series(
        {
            "ê¶Œì¥ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰": recommended,
            "ì „ë…„ëŒ€ë¹„ ê°ì¶•ë¥ ": reduction_yoy,
            "3ê°œë…„ ëŒ€ë¹„ ê°ì¶•ë¥ ": vs3_reduction,
        }
    )


def _compute_org_recommended_and_flags(
    df_org_metrics: pd.DataFrame,
    baseline_by_org: pd.Series,
    spec: dict,
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    org_level_recommended_usage_and_flags + ìƒì„¸ ê´€ë¦¬ëŒ€ìƒ í‘œ.

    âœ” ê¶Œì¥ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰:
       - ì—‘ì…€: '1. ë°±ë°ì´í„° ë¶„ì„'!B7 * (1 - 4.17%)
       - ì—¬ê¸°ì„œëŠ” baseline_by_org * (1 - ndc_rate)
    """
    ndc_rate: float = float(spec["meta"]["ndc_target_rate"])

    cur_usage = df_org_metrics["ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰"]
    share = df_org_metrics["ì—ë„ˆì§€ ì‚¬ìš© ë¹„ì¤‘"]
    upa = df_org_metrics["ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨"]
    growth_rate = df_org_metrics["3ê°œë…„ í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ëŒ€ë¹„ ì¦ê°ë¥ "]

    # âœ… ê¸°ê´€ë³„ ê¶Œì¥ ì‚¬ìš©ëŸ‰ = 3ê°œë…„ í‰ê·  Ã— (1 - ndc_rate)
    recommended = baseline_by_org * (1.0 - ndc_rate)
    usage_vs_recommended = cur_usage / recommended.replace(0, np.nan)

    rank_by_usage = share.rank(ascending=False, method="average")
    rank_by_growth = growth_rate.rank(ascending=False, method="average")
    rank_by_upa = upa.rank(ascending=False, method="average")

    if (
        rank_by_usage.isna().any()
        or rank_by_growth.isna().any()
        or rank_by_upa.isna().any()
    ):
        _log_warning("ì¼ë¶€ ê¸°ê´€ì—ì„œ ìˆœìœ„ ê³„ì‚°ì— NaN ì´ ë°œìƒí•˜ì—¬ ìˆœìœ„ë¥¼ 0ìœ¼ë¡œ í‘œê¸°í•©ë‹ˆë‹¤.")

    rank_by_usage_val = rank_by_usage.fillna(0.0)
    rank_by_growth_val = rank_by_growth.fillna(0.0)
    rank_by_upa_val = rank_by_upa.fillna(0.0)

    upa_mean_overall = float(upa.mean())
    growth_mean_overall = float(growth_rate.mean())
    uv_mean_overall = float(usage_vs_recommended.mean())

    cond_area = upa > upa_mean_overall
    cond_growth = growth_rate > growth_mean_overall
    cond_uv = usage_vs_recommended > uv_mean_overall

    management_flag = (cond_area | cond_growth | cond_uv).fillna(False)
    flag_text = management_flag.map(lambda x: "O" if x else "X")

    df_by_org = pd.DataFrame(
        {
            "ì‚¬ìš© ë¶„í¬ ìˆœìœ„": rank_by_usage_val,
            "ì—ë„ˆì§€ 3ê°œë…„ í‰ê·  ì¦ê°€ ìˆœìœ„": rank_by_growth_val,
            "í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(ì—°ë©´ì  ê¸°ì¤€) ìˆœìœ„": rank_by_upa_val,
            "ê¶Œì¥ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰": recommended,
            "ê¶Œì¥ ì‚¬ìš©ëŸ‰ ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš© ë¹„ìœ¨": usage_vs_recommended,
            "ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ê´€ë¦¬ ëŒ€ìƒ": flag_text,
        },
        index=df_org_metrics.index,
    )

    df_detail = pd.DataFrame(index=df_org_metrics.index)
    df_detail["ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ê³¼ì‚¬ìš©"] = cond_area.fillna(False).map(
        lambda x: "O" if x else "X"
    )
    df_detail["ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ê¸‰ì¦(3ê°œë…„ í‰ê· ëŒ€ë¹„)"] = cond_growth.fillna(False).map(
        lambda x: "O" if x else "X"
    )
    df_detail["ê¶Œì¥ëŸ‰ ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë§¤ìš° ì´ˆê³¼"] = cond_uv.fillna(False).map(
        lambda x: "O" if x else "X"
    )

    return df_by_org, df_detail


def build_data_3_feedback(
    year_to_raw: Mapping[int, pd.DataFrame],
    current_year: Optional[int] = None,
) -> Data3Result:
    spec = load_spec()
    df_all = _concat_raw(year_to_raw)

    if current_year is None:
        current_year = int(spec["meta"]["current_year"])

    # data_2ì™€ ë™ì¼ ë¡œì§ìœ¼ë¡œ ê¸°ê´€ë³„ ì§€í‘œ + 3ê°œë…„ í‰ê· ì„ ì–»ëŠ”ë‹¤
    df_org_metrics, baseline_by_org = _compute_org_level_current_metrics(
        df_all, spec, current_year
    )

    s_overall = _compute_overall_feedback(df_all, spec, current_year, baseline_by_org)
    df_overall = s_overall.to_frame().T
    df_overall.index = ["ê³µë‹¨ ì „ì²´"]

    df_by_org, df_detail = _compute_org_recommended_and_flags(
        df_org_metrics, baseline_by_org, spec
    )

    return Data3Result(overall=df_overall, by_org=df_by_org, detail=df_detail)


# ê¸°ì¡´ app í˜¸í™˜ìš©
def compute_facility_feedback(
    selected_year: int,
    year_to_raw: Mapping[int, pd.DataFrame],
):
    result = build_data_3_feedback(year_to_raw, current_year=selected_year)
    return result.by_org, result.detail
