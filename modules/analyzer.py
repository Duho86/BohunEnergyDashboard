from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, List, Mapping, Optional, Tuple

import numpy as np
import pandas as pd

try:
    import streamlit as st
except ImportError:
    st = None  # type: ignore[assignment]

from .loader import load_spec, get_org_order


# ===============================
# ë¡œê·¸ ìœ í‹¸
# ===============================
def _log_error(msg: str) -> None:
    if st is not None:
        st.error(msg)
    else:
        print("[ERROR]", msg)


def _log_warning(msg: str) -> None:
    if st is not None:
        st.warning(msg)
    else:
        print("[WARN]", msg)


# ===============================
# df_raw ê²°í•©
# ===============================
def _concat_raw(year_to_raw: Mapping[int, pd.DataFrame]) -> pd.DataFrame:
    if not year_to_raw:
        raise ValueError("year_to_raw ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")

    required_cols = ["ê¸°ê´€ëª…", "ì‹œì„¤êµ¬ë¶„", "ì—°ë©´ì ", "ì—°ë‹¨ìœ„", "ì—°ë„"]
    dfs: List[pd.DataFrame] = []

    for year, df in year_to_raw.items():
        if df is None or df.empty:
            continue

        tmp = df.copy()

        # ì—‘ì…€ í•©ê³„í–‰(ê¸°ê´€ëª…='í•©ê³„' & ì—°ë©´ì /ì—°ë‹¨ìœ„ NaN)ì€ ë¯¸ë¦¬ ì œê±°
        if {"ê¸°ê´€ëª…", "ì—°ë©´ì ", "ì—°ë‹¨ìœ„"}.issubset(tmp.columns):
            mask_total = (
                tmp["ê¸°ê´€ëª…"].astype(str).str.strip().eq("í•©ê³„")
                & tmp["ì—°ë©´ì "].isna()
                & tmp["ì—°ë‹¨ìœ„"].isna()
            )
            if mask_total.any():
                tmp = tmp.loc[~mask_total].copy()

        # í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬
        for col in required_cols:
            if col not in tmp.columns:
                raise ValueError(
                    f"{year}ë…„ df_rawì— '{col}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. loader ìŠ¤í‚¤ë§ˆë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”."
                )

        # ìˆ«ì ì»¬ëŸ¼ ì •ì œ
        num_cols = ["ì—°ë„", "ì—°ë©´ì ", "ì—°ë‹¨ìœ„"]
        for col in num_cols:
            tmp[col] = pd.to_numeric(tmp[col], errors="coerce")

        # NaN ìˆëŠ” í–‰ ì œì™¸ + ê²½ê³ 
        na_mask = tmp[num_cols].isna().any(axis=1)
        na_cnt = int(na_mask.sum())
        if na_cnt > 0:
            bad_rows = tmp.loc[na_mask, ["ê¸°ê´€ëª…", "ì—°ë„", "ì—°ë©´ì ", "ì—°ë‹¨ìœ„"]]
            _log_warning(
                f"{year}ë…„ df_rawì—ì„œ ì—°ë„/ì—°ë©´ì /ì—°ë‹¨ìœ„ì— NaN ì´ ìˆëŠ” í–‰ {na_cnt}ê°œë¥¼ ë¶„ì„ì—ì„œ ì œì™¸í•©ë‹ˆë‹¤.\n"
                f"{bad_rows.to_string(index=False)}"
            )
            tmp = tmp.loc[~na_mask].copy()

        dfs.append(tmp)

    if not dfs:
        raise ValueError("ìœ íš¨í•œ df_raw ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    df_all = pd.concat(dfs, ignore_index=True)
    df_all["ì—°ë„"] = df_all["ì—°ë„"].astype(int)
    df_all["ê¸°ê´€ëª…"] = df_all["ê¸°ê´€ëª…"].astype(str)
    df_all["ì‹œì„¤êµ¬ë¶„"] = df_all["ì‹œì„¤êµ¬ë¶„"].astype(str)
    return df_all


# ===============================
# data_2 â€“ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë¶„ì„
# ===============================
@dataclass
class Data2Result:
    overall: pd.DataFrame
    by_org: pd.DataFrame
    baseline_by_org: pd.Series  # ê° ê¸°ê´€ë³„ 3ê°œë…„ í‰ê·  (ì—‘ì…€ B7, U7ì— í•´ë‹¹)


def _compute_overall_usage(
    df_all: pd.DataFrame, spec: dict, current_year: int
) -> pd.Series:
    analysis_years: List[int] = spec["meta"]["analysis_years"]

    if current_year not in analysis_years:
        raise ValueError(
            f"current_year={current_year} ê°€ meta.analysis_years ì— ì—†ìŠµë‹ˆë‹¤."
        )

    prev_year = current_year - 1
    if prev_year not in analysis_years:
        raise ValueError(f"ì „ë…„({prev_year}) ë°ì´í„°ê°€ meta.analysis_years ì— ì—†ìŠµë‹ˆë‹¤.")

    total_by_year = (
        df_all.groupby("ì—°ë„", dropna=False)["ì—°ë‹¨ìœ„"].sum().reindex(analysis_years)
    )
    if total_by_year.isna().any():
        raise ValueError("ì—°ë„ë³„ ì—°ë‹¨ìœ„ í•©ê³„ ê³„ì‚° ì¤‘ NaN ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

    cur = float(total_by_year.loc[current_year])
    prev = float(total_by_year.loc[prev_year])

    past_years = [y for y in analysis_years if y < current_year]
    three_years = past_years[-3:]
    avg3 = float(total_by_year.loc[three_years].mean())

    if prev == 0 or avg3 == 0:
        raise ValueError("ì „ë…„ ë˜ëŠ” 3ê°œë…„ í‰ê·  ì‚¬ìš©ëŸ‰ì´ 0ì…ë‹ˆë‹¤.")

    yoy_rate = (cur - prev) / prev
    vs3_rate = (cur - avg3) / avg3

    return pd.Series(
        {
            "ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(í˜„ì¬ ê¸°ì¤€)": cur,
            "ì „ë…„ëŒ€ë¹„ ì¦ê°ë¥ ": yoy_rate,
            "3ê°œë…„ í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ëŒ€ë¹„ ì¦ê°ë¥ ": vs3_rate,
        }
    )


def _compute_overall_by_facility(df_all: pd.DataFrame, current_year: int) -> pd.Series:
    """
    ì‹œì„¤êµ¬ë¶„ë³„ 'ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨' í‰ê·  ê³„ì‚°.

    ê¸°ì¡´ ì½”ë“œëŠ” ì‹œì„¤êµ¬ë¶„ë³„ (ì—°ë‹¨ìœ„ í•©ê³„ / ì—°ë©´ì  í•©ê³„)ë¡œ ê³„ì‚°í•´ì„œ
    ê¸°ê´€ë³„ ë¹„ìœ¨ì„ ë‹¤ì‹œ í‰ê· ë‚¸ ì—‘ì…€(AAVERAGEIFS)ê³¼ ì°¨ì´ê°€ ë‚¬ë‹¤.

    ì—¬ê¸°ì„œëŠ”:
      1) ê¸°ê´€ë³„ ë©´ì ëŒ€ë¹„ ë¹„ìœ¨ = ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ / ì—°ë©´ì 
      2) ì‹œì„¤êµ¬ë¶„ë³„ë¡œ í•´ë‹¹ ê¸°ê´€ë“¤ì˜ ë¹„ìœ¨ì„ ë‹¨ìˆœ í‰ê· 
    ìœ¼ë¡œ ê³„ì‚°í•´ì„œ ì—‘ì…€ì˜
      =AVERAGEIFS(ì†Œì†ê¸°êµ¬ë³„!Eì—´, ì†Œì†ê¸°êµ¬ë³„!Bì—´, ì‹œì„¤êµ¬ë¶„)
    ê³¼ ìµœëŒ€í•œ ë§ì¶˜ë‹¤.
    """
    df_year = df_all[df_all["ì—°ë„"] == current_year].copy()
    if df_year.empty:
        raise ValueError(f"{current_year}ë…„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # 1) ê¸°ê´€ë³„ ì—°ë‹¨ìœ„ í•©ê³„ / ì—°ë©´ì  ìµœëŒ€ê°’ / ì‹œì„¤êµ¬ë¶„(ëŒ€í‘œê°’)
    usage_by_org = df_year.groupby("ê¸°ê´€ëª…", dropna=False)["ì—°ë‹¨ìœ„"].sum()
    area_by_org = df_year.groupby("ê¸°ê´€ëª…", dropna=False)["ì—°ë©´ì "].max()
    fac_by_org = df_year.groupby("ê¸°ê´€ëª…", dropna=False)["ì‹œì„¤êµ¬ë¶„"].agg(
        lambda x: x.mode().iloc[0] if not x.mode().empty else x.iloc[0]
    )

    # 2) ì‚¬ìš©ëŸ‰ ë˜ëŠ” ë©´ì ì´ 0/NaN ì¸ ê¸°ê´€ ì œì™¸
    valid = (usage_by_org > 0) & (area_by_org > 0)
    usage_by_org = usage_by_org[valid]
    area_by_org = area_by_org[valid]
    fac_by_org = fac_by_org[valid]

    if usage_by_org.empty:
        raise ValueError("ì‹œì„¤êµ¬ë¶„ë³„ ë©´ì ëŒ€ë¹„ ì‚¬ìš©ë¹„ìœ¨ì„ ê³„ì‚°í•  ìœ íš¨í•œ ê¸°ê´€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # 3) ê¸°ê´€ë³„ ë©´ì ëŒ€ë¹„ ì‚¬ìš©ë¹„ìœ¨ = ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ / ì—°ë©´ì 
    upa_org = usage_by_org / area_by_org

    df_fac = pd.DataFrame(
        {
            "ì‹œì„¤êµ¬ë¶„": fac_by_org,
            "ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨": upa_org,
        }
    )

    # 4) ì‹œì„¤êµ¬ë¶„ë³„ë¡œ 'ê¸°ê´€ë³„ ë¹„ìœ¨'ì„ ë‹¨ìˆœ í‰ê· 
    grp = df_fac.groupby("ì‹œì„¤êµ¬ë¶„", dropna=False)["ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨"].mean()

    def get_value(ftype: str) -> float:
        if ftype not in grp.index:
            return float("nan")
        return float(grp.loc[ftype])

    return pd.Series(
        {
            "ì˜ë£Œì‹œì„¤": get_value("ì˜ë£Œì‹œì„¤"),
            "ë³µì§€ì‹œì„¤": get_value("ë³µì§€ì‹œì„¤"),
            "ê¸°íƒ€ì‹œì„¤": get_value("ê¸°íƒ€ì‹œì„¤"),
        }
    )




def _compute_org_level_current_metrics(
    df_all: pd.DataFrame,
    spec: dict,
    current_year: int,
) -> pd.DataFrame:
    """
    org_level_current_year_metrics êµ¬í˜„.

    ë°˜í™˜ ì»¬ëŸ¼:
      ['ì‹œì„¤êµ¬ë¶„','ì—°ë©´ì ','ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰','ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨',
       'ì—ë„ˆì§€ ì‚¬ìš© ë¹„ì¤‘','3ê°œë…„ í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ëŒ€ë¹„ ì¦ê°ë¥ ',
       'ì‹œì„¤ë³„ í‰ê·  ë©´ì  ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨']
    """
    # spec ì— ì •ì˜ëœ year in í•„í„° ì¶”ì¶œ
    calc_conf = None
    for c in spec["logic"]["rules"]["calculations"]:
        if c.get("name") == "org_level_current_year_metrics":
            calc_conf = c
            break

    if calc_conf is None:
        raise ValueError(
            "spec.logic.rules.calculations ì— org_level_current_year_metrics ê°€ ì—†ìŠµë‹ˆë‹¤."
        )

    years_filter: List[int] = []
    for f in calc_conf.get("filters", []):
        if f.get("field") == "year" and f.get("op") == "in":
            years_filter = list(f.get("value", []))
            break

    if not years_filter:
        raise ValueError(
            "org_level_current_year_metrics ì˜ year in í•„í„°ë¥¼ spec ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )

    df = df_all[df_all["ì—°ë„"].isin(years_filter)].copy()
    if df.empty:
        raise ValueError(f"year in {years_filter} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ì—°ë„ë³„ ì—°ë‹¨ìœ„ í•©ê³„ (ì†Œì†ê¸°êµ¬ë³„)
    usage_by_year_org = (
        df.groupby(["ê¸°ê´€ëª…", "ì—°ë„"], dropna=False)["ì—°ë‹¨ìœ„"].sum().unstack("ì—°ë„")
    )

    # ê²°ì¸¡ ì—°ë„ëŠ” 0ìœ¼ë¡œ ë³´ì •
    for y in years_filter:
        if y not in usage_by_year_org.columns:
            usage_by_year_org[y] = 0.0

    usage_by_year_org = usage_by_year_org[sorted(usage_by_year_org.columns)]

    # area, facility_type
    area_by_org = df.groupby("ê¸°ê´€ëª…", dropna=False)["ì—°ë©´ì "].max()
    fac_type_by_org = df.groupby("ê¸°ê´€ëª…", dropna=False)["ì‹œì„¤êµ¬ë¶„"].agg(
        lambda x: x.mode().iloc[0] if not x.mode().empty else x.iloc[0]
    )

    # í˜„ì¬ ì—°ë„ ì‚¬ìš©ëŸ‰
    usage_cur = usage_by_year_org.get(
        current_year, pd.Series(0.0, index=usage_by_year_org.index)
    )

    # ğŸ”¹ current_year ê¸°ì¤€ 'ì§ì „ 3ê°œë…„' í‰ê·  (ì˜ˆ: 2024 â†’ 2021, 2022, 2023)
    years_sorted = sorted(usage_by_year_org.columns)
    if current_year not in years_sorted:
        # ê·¸ë˜ë„ ë­”ê°€ ë‚˜ì˜¤ê²Œ: ì§ì „ 3ê°œë…„ì€ years_filter ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨
        years_sorted = sorted(years_filter)

    prev_years = [y for y in years_sorted if y < current_year]
    three_years = prev_years[-3:]
    if not three_years:
        avg3 = usage_cur.copy()
    else:
        avg3 = usage_by_year_org[three_years].mean(axis=1)

    # 3ê°œë…„ í‰ê·  ëŒ€ë¹„ ì¦ê°ë¥ 
    vs3 = (usage_cur - avg3) / avg3.replace(0, np.nan)

    # ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨ = ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ / ì—°ë©´ì 
    upa = usage_cur / area_by_org.replace(0, np.nan)

    total_cur = float(usage_cur.sum())
    if total_cur == 0:
        raise ValueError("í˜„ì¬ì—°ë„ ì „ì²´ ì‚¬ìš©ëŸ‰ í•©ê³„ê°€ 0ì…ë‹ˆë‹¤.")

    # ì—ë„ˆì§€ ì‚¬ìš© ë¹„ì¤‘
    share = usage_cur / total_cur

    df_org = pd.DataFrame(
        {
            "ì‹œì„¤êµ¬ë¶„": fac_type_by_org,
            "ì—°ë©´ì ": area_by_org,
            "ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰": usage_cur,
            "ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨": upa,
            "ì—ë„ˆì§€ ì‚¬ìš© ë¹„ì¤‘": share,
            "3ê°œë…„ í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ëŒ€ë¹„ ì¦ê°ë¥ ": vs3,
        }
    )

    # ì‹œì„¤ë³„ í‰ê·  ë©´ì  ëŒ€ë¹„ ì‚¬ìš©ë¹„ìœ¨
    facility_mean = df_org.groupby("ì‹œì„¤êµ¬ë¶„", dropna=False)[
        "ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨"
    ].transform("mean")
    df_org["ì‹œì„¤ë³„ í‰ê·  ë©´ì  ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨"] = (
        df_org["ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨"] / facility_mean.replace(0, np.nan)
    )

    # ê¸°ê´€ ê³ ì • ìˆœì„œ ì ìš©
    org_order = list(get_org_order())
    df_org = df_org.reindex(org_order)

    return df_org



def build_data_2_usage_analysis(
    year_to_raw: Mapping[int, pd.DataFrame],
    current_year: Optional[int] = None,
) -> Data2Result:
    spec = load_spec()
    df_all = _concat_raw(year_to_raw)

    if current_year is None:
        current_year = int(spec["meta"]["current_year"])

    s_overall_usage = _compute_overall_usage(df_all, spec, current_year)
    s_fac = _compute_overall_by_facility(df_all, current_year)
    s_all = pd.concat([s_overall_usage, s_fac])
    df_overall = s_all.to_frame().T
    df_overall.index = ["ì „ ì²´"]

    df_by_org, baseline_cur = _compute_org_level_current_metrics(
        df_all, spec, current_year
    )

    return Data2Result(overall=df_overall, by_org=df_by_org, baseline_by_org=baseline_cur)


# ===============================
# data_3 â€“ í”¼ë“œë°±
# ===============================
@dataclass
class Data3Result:
    overall: pd.DataFrame
    by_org: pd.DataFrame
    detail: pd.DataFrame


def _compute_overall_feedback(
    df_all: pd.DataFrame,
    spec: dict,
    current_year: int,
) -> pd.Series:
    """
    ê³µë‹¨ ì „ì²´ í”¼ë“œë°± (ê¶Œì¥ ì‚¬ìš©ëŸ‰ + ê°ì¶•ë¥ ) ê³„ì‚°.

    ì—‘ì…€ê³¼ ìµœëŒ€í•œ ë§ì¶”ê¸° ìœ„í•´,
      - ê¶Œì¥ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰: ê³µë‹¨ ì „ì²´ 3ê°œë…„ í‰ê·  Ã— (1 - NDC)
      - ì „ë…„ëŒ€ë¹„ ê°ì¶•ë¥ : -NDC (ëª©í‘œì¹˜)
      - 3ê°œë…„ ëŒ€ë¹„ ê°ì¶•ë¥ : (ê¶Œì¥ - 3ê°œë…„ í‰ê· ) / 3ê°œë…„ í‰ê· 
    ìœ¼ë¡œ ì •ì˜í•œë‹¤.
    """
    analysis_years: List[int] = spec["meta"]["analysis_years"]
    ndc_rate: float = float(spec["meta"]["ndc_target_rate"])

    total_by_year = (
        df_all.groupby("ì—°ë„", dropna=False)["ì—°ë‹¨ìœ„"].sum().reindex(analysis_years)
    )
    if total_by_year.isna().any():
        raise ValueError("ì—°ë„ë³„ ì—°ë‹¨ìœ„ í•©ê³„ ê³„ì‚° ì¤‘ NaN ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

    # current_year ì´ì „ ì—°ë„ ì¤‘ ë§ˆì§€ë§‰ 3ê°œë…„ (ì˜ˆ: 2021,2022,2023)
    past_years = [y for y in analysis_years if y < current_year]
    three_years = past_years[-3:]
    if not three_years:
        raise ValueError("3ê°œë…„ í‰ê· ì„ ê³„ì‚°í•  ê³¼ê±° ì—°ë„ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    # ê³µë‹¨ ì „ì²´ 3ê°œë…„ í‰ê· 
    avg3 = float(total_by_year.loc[three_years].mean())

    # ğŸ”¹ ê¶Œì¥ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ = 3ê°œë…„ í‰ê·  Ã— (1 - NDC)
    recommended = avg3 * (1.0 - ndc_rate)

    # ì „ë…„ëŒ€ë¹„ ê°ì¶•ë¥ : ì •ì±…ìƒ ëª©í‘œì¹˜ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    reduction_yoy = -ndc_rate

    # 3ê°œë…„ ëŒ€ë¹„ ê°ì¶•ë¥  = (ê¶Œì¥ - 3ê°œë…„ í‰ê· ) / 3ê°œë…„ í‰ê· 
    reduction_vs3 = (recommended - avg3) / avg3

    return pd.Series(
        {
            "ê¶Œì¥ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰": recommended,
            "ì „ë…„ëŒ€ë¹„ ê°ì¶•ë¥ ": reduction_yoy,
            "3ê°œë…„ ëŒ€ë¹„ ê°ì¶•ë¥ ": reduction_vs3,
        }
    )




def _compute_org_recommended_and_flags(
    df_org_metrics: pd.DataFrame,
    spec: dict,
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    org_level_recommended_usage_and_flags + ìƒì„¸ ê´€ë¦¬ëŒ€ìƒ í‘œ ìƒì„±.

    ì—‘ì…€ ê·œì¹™ì— ìµœëŒ€í•œ ë§ì¶”ì–´:
      - ê¶Œì¥ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰: ê¸°ê´€ë³„ 3ê°œë…„ í‰ê·  Ã— (1 - NDC)
      - ê¶Œì¥ ì‚¬ìš©ëŸ‰ ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš© ë¹„ìœ¨: í˜„ì¬ ì‚¬ìš©ëŸ‰ / ê¶Œì¥ ì‚¬ìš©ëŸ‰
      - ê´€ë¦¬ëŒ€ìƒ ì—¬ë¶€: (ë©´ì ëŒ€ë¹„ ê³¼ì‚¬ìš© OR 3ê°œë…„ í‰ê·  ëŒ€ë¹„ ê¸‰ì¦ OR ê¶Œì¥ëŸ‰ ëŒ€ë¹„ ê³¼ì‚¬ìš©)
    """
    ndc_rate: float = float(spec["meta"]["ndc_target_rate"])

    # df_org_metrics ëŠ” _compute_org_level_current_metrics ê²°ê³¼
    cur_usage = df_org_metrics["ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰"]
    vs3_rate = df_org_metrics["3ê°œë…„ í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ëŒ€ë¹„ ì¦ê°ë¥ "]  # (cur - avg3) / avg3
    upa = df_org_metrics["ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ë¹„ìœ¨"]

    # avg3 ê°’ì„ ì—­ì‚°: (cur - avg3) / avg3 = r â†’ cur = avg3 * (1 + r)
    avg3 = cur_usage / (1.0 + vs3_rate.replace(-1.0, np.nan))

    # ğŸ”¹ ê¸°ê´€ë³„ ê¶Œì¥ ì‚¬ìš©ëŸ‰ = 3ê°œë…„ í‰ê·  Ã— (1 - NDC)
    recommended = avg3 * (1.0 - ndc_rate)
    usage_vs_recommended = cur_usage / recommended.replace(0, np.nan)

    # ì„±ì¥ë¥  (3ê°œë…„ í‰ê·  ëŒ€ë¹„)
    growth_rate = (cur_usage - avg3) / avg3.replace(0, np.nan)

    # ìˆœìœ„ ê³„ì‚° (ë‚´ë¦¼ì°¨ìˆœ, 1ë“±ì´ ê°€ì¥ í° ê°’)
    rank_by_usage = cur_usage.rank(ascending=False, method="min")
    rank_by_growth = growth_rate.rank(ascending=False, method="min")
    rank_by_upa = upa.rank(ascending=False, method="min")

    # NaN ìˆœìœ„ëŠ” 0ìœ¼ë¡œ í‘œê¸°
    if (
        rank_by_usage.isna().any()
        or rank_by_growth.isna().any()
        or rank_by_upa.isna().any()
    ):
        _log_warning("ì¼ë¶€ ê¸°ê´€ì—ì„œ ìˆœìœ„ ê³„ì‚°ì— NaN ì´ ë°œìƒí•˜ì—¬ ìˆœìœ„ë¥¼ 0ìœ¼ë¡œ í‘œê¸°í•©ë‹ˆë‹¤.")

    rank_by_usage_val = rank_by_usage.fillna(0.0)
    rank_by_growth_val = rank_by_growth.fillna(0.0)
    rank_by_upa_val = rank_by_upa.fillna(0.0)

    # ì „ì²´ í‰ê· ê°’ (ì—‘ì…€ì˜ í•©ê³„í–‰ ê¸°ì¤€ê³¼ ìœ ì‚¬)
    upa_mean = upa.mean()
    growth_mean = growth_rate.mean()
    uv_mean = usage_vs_recommended.mean()

    # ê´€ë¦¬ëŒ€ìƒ í”Œë˜ê·¸ (ì¡°ê±´1 OR ì¡°ê±´2 OR ì¡°ê±´3)
    cond_area = upa > upa_mean
    cond_growth = growth_rate > growth_mean
    cond_uv = usage_vs_recommended > uv_mean

    flag_series = (
        cond_area.fillna(False)
        | cond_growth.fillna(False)
        | cond_uv.fillna(False)
    ).astype(bool)
    flag_text = flag_series.map(lambda x: "O" if x else "X")

    df_by_org = pd.DataFrame(
        {
            "ì‚¬ìš© ë¶„í¬ ìˆœìœ„": rank_by_usage_val,
            "ì—ë„ˆì§€ 3ê°œë…„ í‰ê·  ì¦ê°€ ìˆœìœ„": rank_by_growth_val,
            "í‰ê·  ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰(ì—°ë©´ì  ê¸°ì¤€) ìˆœìœ„": rank_by_upa_val,
            "ê¶Œì¥ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰": recommended,
            "ê¶Œì¥ ì‚¬ìš©ëŸ‰ ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš© ë¹„ìœ¨": usage_vs_recommended,
            "ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ê´€ë¦¬ ëŒ€ìƒ": flag_text,
        },
        index=df_org_metrics.index,
    )

    # ìƒì„¸ ê´€ë¦¬ëŒ€ìƒ í‘œ â€“ ê° ì¡°ê±´ì„ ê·¸ëŒ€ë¡œ ë…¸ì¶œ
    detail_cols: Dict[str, pd.Series] = {}
    detail_cols["ë©´ì ëŒ€ë¹„ ì—ë„ˆì§€ ê³¼ì‚¬ìš©"] = cond_area
    detail_cols["ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ê¸‰ì¦(3ê°œë…„ í‰ê· ëŒ€ë¹„)"] = cond_growth
    detail_cols["ê¶Œì¥ëŸ‰ ëŒ€ë¹„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë§¤ìš° ì´ˆê³¼"] = cond_uv

    df_detail = pd.DataFrame(index=df_org_metrics.index)
    for col_name, cond in detail_cols.items():
        cond_bool = cond.fillna(False).astype(bool)
        df_detail[col_name] = cond_bool.map(lambda x: "O" if x else "X")

    return df_by_org, df_detail




def build_data_3_feedback(
    year_to_raw: Mapping[int, pd.DataFrame],
    current_year: Optional[int] = None,
) -> Data3Result:
    spec = load_spec()
    df_all = _concat_raw(year_to_raw)

    if current_year is None:
        current_year = int(spec["meta"]["current_year"])

    # data_2ì™€ ë™ì¼ ë¡œì§ìœ¼ë¡œ ê¸°ê´€ë³„ ì§€í‘œ + 3ê°œë…„ í‰ê· ì„ ì–»ëŠ”ë‹¤
    df_org_metrics, baseline_by_org = _compute_org_level_current_metrics(
        df_all, spec, current_year
    )

    s_overall = _compute_overall_feedback(df_all, spec, current_year, baseline_by_org)
    df_overall = s_overall.to_frame().T
    df_overall.index = ["ê³µë‹¨ ì „ì²´"]

    df_by_org, df_detail = _compute_org_recommended_and_flags(
        df_org_metrics, baseline_by_org, spec
    )

    return Data3Result(overall=df_overall, by_org=df_by_org, detail=df_detail)


# ê¸°ì¡´ app í˜¸í™˜ìš©
def compute_facility_feedback(
    selected_year: int,
    year_to_raw: Mapping[int, pd.DataFrame],
):
    result = build_data_3_feedback(year_to_raw, current_year=selected_year)
    return result.by_org, result.detail
